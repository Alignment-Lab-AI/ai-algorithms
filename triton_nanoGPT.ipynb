{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP9wimLpfHAm",
        "outputId": "dc548739-b176-4a86-ae0b-526bf56f3683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-IEnBDmHO3A",
        "outputId": "cada8fc8-1cf8-4578-eb3e-79932778ae9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists at input.txt.\n",
            "Vocabulary size: 65\n",
            "Training data size: 1003854 characters\n",
            "Testing data size: 111540 characters\n",
            "Using device: cuda\n",
            "iter 10: loss 4.1652, time 152.40ms, mfu 2.47%\n",
            "iter 20: loss 4.1571, time 152.94ms, mfu 2.46%\n",
            "iter 30: loss 4.1501, time 151.89ms, mfu 2.48%\n",
            "iter 40: loss 4.1417, time 154.25ms, mfu 2.44%\n",
            "iter 50: loss 4.1374, time 154.14ms, mfu 2.44%\n",
            "iter 60: loss 4.1286, time 153.57ms, mfu 2.45%\n",
            "iter 70: loss 4.1248, time 154.99ms, mfu 2.43%\n",
            "iter 80: loss 4.1182, time 153.84ms, mfu 2.45%\n",
            "iter 90: loss 4.1100, time 155.30ms, mfu 2.43%\n",
            "iter 100: loss 4.1121, time 154.10ms, mfu 2.44%\n",
            "Epoch 1/100, Validation Loss: 4.1079\n",
            "Saved checkpoint for validation loss: 4.1079\n",
            "iter 110: loss 4.1024, time 156.29ms, mfu 2.41%\n",
            "iter 120: loss 4.0924, time 157.12ms, mfu 2.40%\n",
            "iter 130: loss 4.0866, time 154.83ms, mfu 2.43%\n",
            "iter 140: loss 4.0811, time 154.79ms, mfu 2.43%\n",
            "iter 150: loss 4.0749, time 156.28ms, mfu 2.41%\n",
            "iter 160: loss 4.0680, time 156.72ms, mfu 2.40%\n",
            "iter 170: loss 4.0605, time 153.87ms, mfu 2.45%\n",
            "iter 180: loss 4.0540, time 155.34ms, mfu 2.42%\n",
            "iter 190: loss 4.0490, time 155.58ms, mfu 2.42%\n",
            "iter 200: loss 4.0410, time 152.21ms, mfu 2.47%\n",
            "Epoch 2/100, Validation Loss: 4.0470\n",
            "Saved checkpoint for validation loss: 4.0470\n",
            "iter 210: loss 4.0395, time 152.35ms, mfu 2.47%\n",
            "iter 220: loss 4.0340, time 153.05ms, mfu 2.46%\n",
            "iter 230: loss 4.0270, time 153.17ms, mfu 2.46%\n",
            "iter 240: loss 4.0274, time 153.35ms, mfu 2.46%\n",
            "iter 250: loss 4.0174, time 151.64ms, mfu 2.48%\n",
            "iter 260: loss 4.0111, time 152.93ms, mfu 2.46%\n",
            "iter 270: loss 4.0077, time 153.11ms, mfu 2.46%\n",
            "iter 280: loss 4.0003, time 153.65ms, mfu 2.45%\n",
            "iter 290: loss 4.0020, time 152.98ms, mfu 2.46%\n",
            "iter 300: loss 3.9857, time 154.00ms, mfu 2.45%\n",
            "Epoch 3/100, Validation Loss: 3.9919\n",
            "Saved checkpoint for validation loss: 3.9919\n",
            "iter 310: loss 3.9864, time 153.72ms, mfu 2.45%\n",
            "iter 320: loss 3.9732, time 154.27ms, mfu 2.44%\n",
            "iter 330: loss 3.9751, time 152.57ms, mfu 2.47%\n",
            "iter 340: loss 3.9630, time 152.33ms, mfu 2.47%\n",
            "iter 350: loss 3.9550, time 153.40ms, mfu 2.46%\n",
            "iter 360: loss 3.9540, time 151.97ms, mfu 2.48%\n",
            "iter 370: loss 3.9530, time 154.48ms, mfu 2.44%\n",
            "iter 380: loss 3.9421, time 153.39ms, mfu 2.46%\n",
            "iter 390: loss 3.9462, time 154.23ms, mfu 2.44%\n",
            "iter 400: loss 3.9319, time 156.68ms, mfu 2.40%\n",
            "Epoch 4/100, Validation Loss: 3.9402\n",
            "Saved checkpoint for validation loss: 3.9402\n",
            "iter 410: loss 3.9299, time 154.00ms, mfu 2.45%\n",
            "iter 420: loss 3.9281, time 154.75ms, mfu 2.43%\n",
            "iter 430: loss 3.9190, time 153.15ms, mfu 2.46%\n",
            "iter 440: loss 3.9180, time 155.06ms, mfu 2.43%\n",
            "iter 450: loss 3.9095, time 153.45ms, mfu 2.45%\n",
            "iter 460: loss 3.8993, time 154.13ms, mfu 2.44%\n",
            "iter 470: loss 3.9007, time 155.01ms, mfu 2.43%\n",
            "iter 480: loss 3.8968, time 154.55ms, mfu 2.44%\n",
            "iter 490: loss 3.8963, time 154.37ms, mfu 2.44%\n",
            "iter 500: loss 3.8887, time 153.19ms, mfu 2.46%\n",
            "Epoch 5/100, Validation Loss: 3.8907\n",
            "Saved checkpoint for validation loss: 3.8907\n",
            "iter 510: loss 3.8810, time 154.87ms, mfu 2.43%\n",
            "iter 520: loss 3.8826, time 153.75ms, mfu 2.45%\n",
            "iter 530: loss 3.8655, time 153.32ms, mfu 2.46%\n",
            "iter 540: loss 3.8725, time 154.56ms, mfu 2.44%\n",
            "iter 550: loss 3.8575, time 156.44ms, mfu 2.41%\n",
            "iter 560: loss 3.8601, time 154.26ms, mfu 2.44%\n",
            "iter 570: loss 3.8527, time 154.68ms, mfu 2.44%\n",
            "iter 580: loss 3.8511, time 153.58ms, mfu 2.45%\n",
            "iter 590: loss 3.8393, time 154.37ms, mfu 2.44%\n",
            "iter 600: loss 3.8430, time 153.95ms, mfu 2.45%\n",
            "Epoch 6/100, Validation Loss: 3.8467\n",
            "Saved checkpoint for validation loss: 3.8467\n",
            "iter 610: loss 3.8409, time 154.66ms, mfu 2.44%\n",
            "iter 620: loss 3.8280, time 154.83ms, mfu 2.43%\n",
            "iter 630: loss 3.8227, time 152.06ms, mfu 2.48%\n",
            "iter 640: loss 3.8203, time 153.80ms, mfu 2.45%\n",
            "iter 650: loss 3.8155, time 152.58ms, mfu 2.47%\n",
            "iter 660: loss 3.8001, time 153.50ms, mfu 2.45%\n",
            "iter 670: loss 3.8073, time 152.14ms, mfu 2.48%\n",
            "iter 680: loss 3.8072, time 155.29ms, mfu 2.43%\n",
            "iter 690: loss 3.7940, time 155.47ms, mfu 2.42%\n",
            "iter 700: loss 3.7925, time 152.25ms, mfu 2.47%\n",
            "Epoch 7/100, Validation Loss: 3.8023\n",
            "Saved checkpoint for validation loss: 3.8023\n",
            "iter 710: loss 3.7924, time 154.21ms, mfu 2.44%\n",
            "iter 720: loss 3.7899, time 155.05ms, mfu 2.43%\n",
            "iter 730: loss 3.7807, time 154.41ms, mfu 2.44%\n",
            "iter 740: loss 3.7714, time 153.59ms, mfu 2.45%\n",
            "iter 750: loss 3.7730, time 153.95ms, mfu 2.45%\n",
            "iter 760: loss 3.7641, time 154.01ms, mfu 2.45%\n",
            "iter 770: loss 3.7704, time 153.99ms, mfu 2.45%\n",
            "iter 780: loss 3.7655, time 153.77ms, mfu 2.45%\n",
            "iter 790: loss 3.7571, time 154.45ms, mfu 2.44%\n",
            "iter 800: loss 3.7456, time 156.32ms, mfu 2.41%\n",
            "Epoch 8/100, Validation Loss: 3.7584\n",
            "Saved checkpoint for validation loss: 3.7584\n",
            "iter 810: loss 3.7571, time 154.69ms, mfu 2.43%\n",
            "iter 820: loss 3.7479, time 153.43ms, mfu 2.45%\n",
            "iter 830: loss 3.7388, time 153.95ms, mfu 2.45%\n",
            "iter 840: loss 3.7345, time 157.10ms, mfu 2.40%\n",
            "iter 850: loss 3.7303, time 155.45ms, mfu 2.42%\n",
            "iter 860: loss 3.7281, time 154.09ms, mfu 2.44%\n",
            "iter 870: loss 3.7300, time 153.37ms, mfu 2.46%\n",
            "iter 880: loss 3.7175, time 153.31ms, mfu 2.46%\n",
            "iter 890: loss 3.7195, time 162.55ms, mfu 2.32%\n",
            "iter 900: loss 3.7174, time 152.76ms, mfu 2.47%\n",
            "Epoch 9/100, Validation Loss: 3.7198\n",
            "Saved checkpoint for validation loss: 3.7198\n",
            "iter 910: loss 3.7239, time 152.26ms, mfu 2.47%\n",
            "iter 920: loss 3.7094, time 154.07ms, mfu 2.44%\n",
            "iter 930: loss 3.7077, time 153.09ms, mfu 2.46%\n",
            "iter 940: loss 3.6955, time 153.95ms, mfu 2.45%\n",
            "iter 950: loss 3.6945, time 154.00ms, mfu 2.45%\n",
            "iter 960: loss 3.6863, time 154.54ms, mfu 2.44%\n",
            "iter 970: loss 3.6824, time 155.20ms, mfu 2.43%\n",
            "iter 980: loss 3.6872, time 154.50ms, mfu 2.44%\n",
            "iter 990: loss 3.6762, time 154.10ms, mfu 2.44%\n",
            "iter 1000: loss 3.6701, time 151.72ms, mfu 2.48%\n",
            "Epoch 10/100, Validation Loss: 3.6882\n",
            "Saved checkpoint for validation loss: 3.6882\n",
            "iter 1010: loss 3.6904, time 153.34ms, mfu 2.46%\n",
            "iter 1020: loss 3.6864, time 153.80ms, mfu 2.45%\n",
            "iter 1030: loss 3.6724, time 153.95ms, mfu 2.45%\n",
            "iter 1040: loss 3.6704, time 152.16ms, mfu 2.48%\n",
            "iter 1050: loss 3.6507, time 153.37ms, mfu 2.46%\n",
            "iter 1060: loss 3.6609, time 154.10ms, mfu 2.44%\n",
            "iter 1070: loss 3.6597, time 153.81ms, mfu 2.45%\n",
            "iter 1080: loss 3.6530, time 154.81ms, mfu 2.43%\n",
            "iter 1090: loss 3.6442, time 154.34ms, mfu 2.44%\n",
            "iter 1100: loss 3.6374, time 156.85ms, mfu 2.40%\n",
            "Epoch 11/100, Validation Loss: 3.6537\n",
            "Saved checkpoint for validation loss: 3.6537\n",
            "iter 1110: loss 3.6412, time 153.49ms, mfu 2.45%\n",
            "iter 1120: loss 3.6407, time 156.15ms, mfu 2.41%\n",
            "iter 1130: loss 3.6329, time 155.15ms, mfu 2.43%\n",
            "iter 1140: loss 3.6226, time 153.72ms, mfu 2.45%\n",
            "iter 1150: loss 3.6216, time 154.04ms, mfu 2.45%\n",
            "iter 1160: loss 3.6167, time 152.88ms, mfu 2.46%\n",
            "iter 1170: loss 3.6270, time 152.78ms, mfu 2.47%\n",
            "iter 1180: loss 3.6125, time 152.99ms, mfu 2.46%\n",
            "iter 1190: loss 3.6172, time 152.25ms, mfu 2.47%\n",
            "iter 1200: loss 3.6271, time 155.31ms, mfu 2.43%\n",
            "Epoch 12/100, Validation Loss: 3.6268\n",
            "Saved checkpoint for validation loss: 3.6268\n",
            "iter 1210: loss 3.6342, time 153.91ms, mfu 2.45%\n",
            "iter 1220: loss 3.6039, time 155.33ms, mfu 2.42%\n",
            "iter 1230: loss 3.6028, time 153.26ms, mfu 2.46%\n",
            "iter 1240: loss 3.5954, time 155.24ms, mfu 2.43%\n",
            "iter 1250: loss 3.5897, time 154.28ms, mfu 2.44%\n",
            "iter 1260: loss 3.5866, time 152.90ms, mfu 2.46%\n",
            "iter 1270: loss 3.5850, time 153.39ms, mfu 2.46%\n",
            "iter 1280: loss 3.5796, time 151.84ms, mfu 2.48%\n",
            "iter 1290: loss 3.5892, time 153.42ms, mfu 2.46%\n",
            "iter 1300: loss 3.5829, time 153.66ms, mfu 2.45%\n",
            "Epoch 13/100, Validation Loss: 3.5967\n",
            "Saved checkpoint for validation loss: 3.5967\n",
            "iter 1310: loss 3.5832, time 153.56ms, mfu 2.45%\n",
            "iter 1320: loss 3.5860, time 155.38ms, mfu 2.42%\n",
            "iter 1330: loss 3.5736, time 153.04ms, mfu 2.46%\n",
            "iter 1340: loss 3.5733, time 152.58ms, mfu 2.47%\n",
            "iter 1350: loss 3.5812, time 152.89ms, mfu 2.46%\n",
            "iter 1360: loss 3.5507, time 154.86ms, mfu 2.43%\n",
            "iter 1370: loss 3.5654, time 156.03ms, mfu 2.41%\n",
            "iter 1380: loss 3.5577, time 153.30ms, mfu 2.46%\n",
            "iter 1390: loss 3.5526, time 152.56ms, mfu 2.47%\n",
            "iter 1400: loss 3.5616, time 152.70ms, mfu 2.47%\n",
            "Epoch 14/100, Validation Loss: 3.5679\n",
            "Saved checkpoint for validation loss: 3.5679\n",
            "iter 1410: loss 3.5729, time 154.28ms, mfu 2.44%\n",
            "iter 1420: loss 3.5434, time 154.88ms, mfu 2.43%\n",
            "iter 1430: loss 3.5489, time 154.00ms, mfu 2.45%\n",
            "iter 1440: loss 3.5465, time 152.48ms, mfu 2.47%\n",
            "iter 1450: loss 3.5471, time 152.69ms, mfu 2.47%\n",
            "iter 1460: loss 3.5253, time 152.58ms, mfu 2.47%\n",
            "iter 1470: loss 3.5316, time 152.22ms, mfu 2.47%\n",
            "iter 1480: loss 3.5241, time 152.62ms, mfu 2.47%\n",
            "iter 1490: loss 3.5269, time 188.88ms, mfu 1.99%\n",
            "iter 1500: loss 3.5117, time 156.87ms, mfu 2.40%\n",
            "Epoch 15/100, Validation Loss: 3.5404\n",
            "Saved checkpoint for validation loss: 3.5404\n",
            "iter 1510: loss 3.5108, time 151.72ms, mfu 2.48%\n",
            "iter 1520: loss 3.5214, time 153.05ms, mfu 2.46%\n",
            "iter 1530: loss 3.5180, time 154.54ms, mfu 2.44%\n",
            "iter 1540: loss 3.5093, time 154.41ms, mfu 2.44%\n",
            "iter 1550: loss 3.5182, time 153.49ms, mfu 2.45%\n",
            "iter 1560: loss 3.5074, time 152.94ms, mfu 2.46%\n",
            "iter 1570: loss 3.4999, time 153.51ms, mfu 2.45%\n",
            "iter 1580: loss 3.4998, time 153.40ms, mfu 2.46%\n",
            "iter 1590: loss 3.4977, time 152.51ms, mfu 2.47%\n",
            "iter 1600: loss 3.5045, time 152.67ms, mfu 2.47%\n",
            "Epoch 16/100, Validation Loss: 3.5164\n",
            "Saved checkpoint for validation loss: 3.5164\n",
            "iter 1610: loss 3.4925, time 153.78ms, mfu 2.45%\n",
            "iter 1620: loss 3.4976, time 153.89ms, mfu 2.45%\n",
            "iter 1630: loss 3.4956, time 155.03ms, mfu 2.43%\n",
            "iter 1640: loss 3.5012, time 154.33ms, mfu 2.44%\n",
            "iter 1650: loss 3.4785, time 153.83ms, mfu 2.45%\n",
            "iter 1660: loss 3.4943, time 156.24ms, mfu 2.41%\n",
            "iter 1670: loss 3.4770, time 155.09ms, mfu 2.43%\n",
            "iter 1680: loss 3.4793, time 153.36ms, mfu 2.46%\n",
            "iter 1690: loss 3.4731, time 152.65ms, mfu 2.47%\n",
            "iter 1700: loss 3.4601, time 153.23ms, mfu 2.46%\n",
            "Epoch 17/100, Validation Loss: 3.4933\n",
            "Saved checkpoint for validation loss: 3.4933\n",
            "iter 1710: loss 3.4661, time 159.46ms, mfu 2.36%\n",
            "iter 1720: loss 3.4639, time 153.92ms, mfu 2.45%\n",
            "iter 1730: loss 3.4575, time 153.75ms, mfu 2.45%\n",
            "iter 1740: loss 3.4591, time 153.08ms, mfu 2.46%\n",
            "iter 1750: loss 3.4716, time 154.70ms, mfu 2.43%\n",
            "iter 1760: loss 3.4720, time 153.56ms, mfu 2.45%\n",
            "iter 1770: loss 3.4668, time 155.32ms, mfu 2.43%\n",
            "iter 1780: loss 3.4543, time 153.10ms, mfu 2.46%\n",
            "iter 1790: loss 3.4536, time 153.64ms, mfu 2.45%\n",
            "iter 1800: loss 3.4547, time 153.40ms, mfu 2.46%\n",
            "Epoch 18/100, Validation Loss: 3.4718\n",
            "Saved checkpoint for validation loss: 3.4718\n",
            "iter 1810: loss 3.4620, time 154.37ms, mfu 2.44%\n",
            "iter 1820: loss 3.4527, time 153.53ms, mfu 2.45%\n",
            "iter 1830: loss 3.4296, time 153.93ms, mfu 2.45%\n",
            "iter 1840: loss 3.4428, time 154.52ms, mfu 2.44%\n",
            "iter 1850: loss 3.4271, time 154.15ms, mfu 2.44%\n",
            "iter 1860: loss 3.4407, time 154.70ms, mfu 2.43%\n",
            "iter 1870: loss 3.4207, time 154.57ms, mfu 2.44%\n",
            "iter 1880: loss 3.4245, time 153.75ms, mfu 2.45%\n",
            "iter 1890: loss 3.4267, time 155.08ms, mfu 2.43%\n",
            "iter 1900: loss 3.4286, time 154.30ms, mfu 2.44%\n",
            "Epoch 19/100, Validation Loss: 3.4526\n",
            "Saved checkpoint for validation loss: 3.4526\n",
            "iter 1910: loss 3.4213, time 151.55ms, mfu 2.49%\n",
            "iter 1920: loss 3.4217, time 155.19ms, mfu 2.43%\n",
            "iter 1930: loss 3.4313, time 154.16ms, mfu 2.44%\n",
            "iter 1940: loss 3.4278, time 153.10ms, mfu 2.46%\n",
            "iter 1950: loss 3.4326, time 153.41ms, mfu 2.46%\n",
            "iter 1960: loss 3.4074, time 152.78ms, mfu 2.47%\n",
            "iter 1970: loss 3.3905, time 152.28ms, mfu 2.47%\n",
            "iter 1980: loss 3.4019, time 152.66ms, mfu 2.47%\n",
            "iter 1990: loss 3.4007, time 153.29ms, mfu 2.46%\n",
            "iter 2000: loss 3.4210, time 153.12ms, mfu 2.46%\n",
            "Epoch 20/100, Validation Loss: 3.4229\n",
            "Saved checkpoint for validation loss: 3.4229\n",
            "iter 2010: loss 3.4071, time 155.70ms, mfu 2.42%\n",
            "iter 2020: loss 3.4158, time 153.26ms, mfu 2.46%\n",
            "iter 2030: loss 3.3946, time 151.38ms, mfu 2.49%\n",
            "iter 2040: loss 3.4053, time 152.41ms, mfu 2.47%\n",
            "iter 2050: loss 3.4136, time 154.72ms, mfu 2.43%\n",
            "iter 2060: loss 3.3922, time 152.93ms, mfu 2.46%\n",
            "iter 2070: loss 3.4073, time 153.70ms, mfu 2.45%\n",
            "iter 2080: loss 3.3779, time 156.50ms, mfu 2.41%\n",
            "iter 2090: loss 3.3801, time 153.12ms, mfu 2.46%\n",
            "iter 2100: loss 3.3827, time 153.46ms, mfu 2.45%\n",
            "Epoch 21/100, Validation Loss: 3.4062\n",
            "Saved checkpoint for validation loss: 3.4062\n",
            "iter 2110: loss 3.3887, time 153.35ms, mfu 2.46%\n",
            "iter 2120: loss 3.3758, time 154.09ms, mfu 2.44%\n",
            "iter 2130: loss 3.3716, time 153.39ms, mfu 2.46%\n",
            "iter 2140: loss 3.3860, time 152.91ms, mfu 2.46%\n",
            "iter 2150: loss 3.3677, time 153.99ms, mfu 2.45%\n",
            "iter 2160: loss 3.3754, time 152.45ms, mfu 2.47%\n",
            "iter 2170: loss 3.3750, time 153.04ms, mfu 2.46%\n",
            "iter 2180: loss 3.3737, time 154.61ms, mfu 2.44%\n",
            "iter 2190: loss 3.3586, time 158.57ms, mfu 2.38%\n",
            "iter 2200: loss 3.3629, time 153.73ms, mfu 2.45%\n",
            "Epoch 22/100, Validation Loss: 3.3831\n",
            "Saved checkpoint for validation loss: 3.3831\n",
            "iter 2210: loss 3.3782, time 154.97ms, mfu 2.43%\n",
            "iter 2220: loss 3.3515, time 153.55ms, mfu 2.45%\n",
            "iter 2230: loss 3.3665, time 154.97ms, mfu 2.43%\n",
            "iter 2240: loss 3.3549, time 155.02ms, mfu 2.43%\n",
            "iter 2250: loss 3.3644, time 155.57ms, mfu 2.42%\n",
            "iter 2260: loss 3.3502, time 153.83ms, mfu 2.45%\n",
            "iter 2270: loss 3.3313, time 154.42ms, mfu 2.44%\n",
            "iter 2280: loss 3.3413, time 152.69ms, mfu 2.47%\n",
            "iter 2290: loss 3.3685, time 154.55ms, mfu 2.44%\n",
            "iter 2300: loss 3.3479, time 155.09ms, mfu 2.43%\n",
            "Epoch 23/100, Validation Loss: 3.3694\n",
            "Saved checkpoint for validation loss: 3.3694\n",
            "iter 2310: loss 3.3542, time 153.54ms, mfu 2.45%\n",
            "iter 2320: loss 3.3414, time 153.72ms, mfu 2.45%\n",
            "iter 2330: loss 3.3429, time 153.32ms, mfu 2.46%\n",
            "iter 2340: loss 3.3285, time 153.23ms, mfu 2.46%\n",
            "iter 2350: loss 3.3503, time 153.18ms, mfu 2.46%\n",
            "iter 2360: loss 3.3410, time 152.38ms, mfu 2.47%\n",
            "iter 2370: loss 3.3483, time 151.84ms, mfu 2.48%\n",
            "iter 2380: loss 3.3333, time 152.34ms, mfu 2.47%\n",
            "iter 2390: loss 3.3248, time 154.75ms, mfu 2.43%\n",
            "iter 2400: loss 3.3292, time 153.26ms, mfu 2.46%\n",
            "Epoch 24/100, Validation Loss: 3.3526\n",
            "Saved checkpoint for validation loss: 3.3526\n",
            "iter 2410: loss 3.3347, time 152.40ms, mfu 2.47%\n",
            "iter 2420: loss 3.3456, time 153.74ms, mfu 2.45%\n",
            "iter 2430: loss 3.3396, time 158.91ms, mfu 2.37%\n",
            "iter 2440: loss 3.3125, time 152.02ms, mfu 2.48%\n",
            "iter 2450: loss 3.3134, time 152.71ms, mfu 2.47%\n",
            "iter 2460: loss 3.3192, time 154.39ms, mfu 2.44%\n",
            "iter 2470: loss 3.3361, time 154.40ms, mfu 2.44%\n",
            "iter 2480: loss 3.3208, time 153.36ms, mfu 2.46%\n",
            "iter 2490: loss 3.3159, time 154.49ms, mfu 2.44%\n",
            "iter 2500: loss 3.3140, time 153.25ms, mfu 2.46%\n",
            "Epoch 25/100, Validation Loss: 3.3384\n",
            "Saved checkpoint for validation loss: 3.3384\n",
            "iter 2510: loss 3.3483, time 155.33ms, mfu 2.42%\n",
            "iter 2520: loss 3.3063, time 153.55ms, mfu 2.45%\n",
            "iter 2530: loss 3.3189, time 153.97ms, mfu 2.45%\n",
            "iter 2540: loss 3.3126, time 153.73ms, mfu 2.45%\n",
            "iter 2550: loss 3.3079, time 154.65ms, mfu 2.44%\n",
            "iter 2560: loss 3.3197, time 153.81ms, mfu 2.45%\n",
            "iter 2570: loss 3.3260, time 154.58ms, mfu 2.44%\n",
            "iter 2580: loss 3.2922, time 155.18ms, mfu 2.43%\n",
            "iter 2590: loss 3.2987, time 153.80ms, mfu 2.45%\n",
            "iter 2600: loss 3.2981, time 157.12ms, mfu 2.40%\n",
            "Epoch 26/100, Validation Loss: 3.3221\n",
            "Saved checkpoint for validation loss: 3.3221\n",
            "iter 2610: loss 3.3018, time 153.12ms, mfu 2.46%\n",
            "iter 2620: loss 3.2972, time 155.65ms, mfu 2.42%\n",
            "iter 2630: loss 3.2947, time 155.07ms, mfu 2.43%\n",
            "iter 2640: loss 3.2929, time 152.88ms, mfu 2.46%\n",
            "iter 2650: loss 3.2960, time 153.45ms, mfu 2.45%\n",
            "iter 2660: loss 3.2860, time 154.34ms, mfu 2.44%\n",
            "iter 2670: loss 3.2982, time 153.70ms, mfu 2.45%\n",
            "iter 2680: loss 3.2868, time 154.51ms, mfu 2.44%\n",
            "iter 2690: loss 3.2781, time 152.60ms, mfu 2.47%\n",
            "iter 2700: loss 3.2562, time 158.52ms, mfu 2.38%\n",
            "Epoch 27/100, Validation Loss: 3.3025\n",
            "Saved checkpoint for validation loss: 3.3025\n",
            "iter 2710: loss 3.2998, time 152.11ms, mfu 2.48%\n",
            "iter 2720: loss 3.2825, time 154.30ms, mfu 2.44%\n",
            "iter 2730: loss 3.2820, time 152.89ms, mfu 2.46%\n",
            "iter 2740: loss 3.2949, time 154.71ms, mfu 2.43%\n",
            "iter 2750: loss 3.2767, time 165.95ms, mfu 2.27%\n",
            "iter 2760: loss 3.2839, time 153.94ms, mfu 2.45%\n",
            "iter 2770: loss 3.2722, time 155.01ms, mfu 2.43%\n",
            "iter 2780: loss 3.2653, time 152.64ms, mfu 2.47%\n",
            "iter 2790: loss 3.2698, time 154.59ms, mfu 2.44%\n",
            "iter 2800: loss 3.2522, time 152.72ms, mfu 2.47%\n",
            "Epoch 28/100, Validation Loss: 3.2939\n",
            "Saved checkpoint for validation loss: 3.2939\n",
            "iter 2810: loss 3.2686, time 154.71ms, mfu 2.43%\n",
            "iter 2820: loss 3.2532, time 154.64ms, mfu 2.44%\n",
            "iter 2830: loss 3.2679, time 160.13ms, mfu 2.35%\n",
            "iter 2840: loss 3.2624, time 152.93ms, mfu 2.46%\n",
            "iter 2850: loss 3.2594, time 152.40ms, mfu 2.47%\n",
            "iter 2860: loss 3.2644, time 154.18ms, mfu 2.44%\n",
            "iter 2870: loss 3.2592, time 155.11ms, mfu 2.43%\n",
            "iter 2880: loss 3.2586, time 152.46ms, mfu 2.47%\n",
            "iter 2890: loss 3.2545, time 153.79ms, mfu 2.45%\n",
            "iter 2900: loss 3.2370, time 153.69ms, mfu 2.45%\n",
            "Epoch 29/100, Validation Loss: 3.2792\n",
            "Saved checkpoint for validation loss: 3.2792\n",
            "iter 2910: loss 3.2637, time 154.32ms, mfu 2.44%\n",
            "iter 2920: loss 3.2437, time 154.78ms, mfu 2.43%\n",
            "iter 2930: loss 3.2604, time 154.50ms, mfu 2.44%\n",
            "iter 2940: loss 3.2481, time 152.83ms, mfu 2.46%\n",
            "iter 2950: loss 3.2474, time 153.44ms, mfu 2.45%\n",
            "iter 2960: loss 3.2564, time 155.01ms, mfu 2.43%\n",
            "iter 2970: loss 3.2595, time 154.59ms, mfu 2.44%\n",
            "iter 2980: loss 3.2476, time 155.61ms, mfu 2.42%\n",
            "iter 2990: loss 3.2323, time 155.64ms, mfu 2.42%\n",
            "iter 3000: loss 3.2342, time 156.38ms, mfu 2.41%\n",
            "Epoch 30/100, Validation Loss: 3.2676\n",
            "Saved checkpoint for validation loss: 3.2676\n",
            "iter 3010: loss 3.2476, time 153.21ms, mfu 2.46%\n",
            "iter 3020: loss 3.2325, time 153.85ms, mfu 2.45%\n",
            "iter 3030: loss 3.2534, time 154.26ms, mfu 2.44%\n",
            "iter 3040: loss 3.2236, time 153.78ms, mfu 2.45%\n",
            "iter 3050: loss 3.2349, time 153.48ms, mfu 2.45%\n",
            "iter 3060: loss 3.2344, time 154.06ms, mfu 2.44%\n",
            "iter 3070: loss 3.2312, time 153.10ms, mfu 2.46%\n",
            "iter 3080: loss 3.2258, time 154.17ms, mfu 2.44%\n",
            "iter 3090: loss 3.2430, time 152.72ms, mfu 2.47%\n",
            "iter 3100: loss 3.2283, time 154.35ms, mfu 2.44%\n",
            "Epoch 31/100, Validation Loss: 3.2465\n",
            "Saved checkpoint for validation loss: 3.2465\n",
            "iter 3110: loss 3.2120, time 153.69ms, mfu 2.45%\n",
            "iter 3120: loss 3.2189, time 151.44ms, mfu 2.49%\n",
            "iter 3130: loss 3.2275, time 153.24ms, mfu 2.46%\n",
            "iter 3140: loss 3.2032, time 153.00ms, mfu 2.46%\n",
            "iter 3150: loss 3.2177, time 155.46ms, mfu 2.42%\n",
            "iter 3160: loss 3.2142, time 153.20ms, mfu 2.46%\n",
            "iter 3170: loss 3.2249, time 150.70ms, mfu 2.50%\n",
            "iter 3180: loss 3.2082, time 152.95ms, mfu 2.46%\n",
            "iter 3190: loss 3.2056, time 152.14ms, mfu 2.48%\n",
            "iter 3200: loss 3.2197, time 153.98ms, mfu 2.45%\n",
            "Epoch 32/100, Validation Loss: 3.2434\n",
            "Saved checkpoint for validation loss: 3.2434\n",
            "iter 3210: loss 3.2222, time 153.49ms, mfu 2.45%\n",
            "iter 3220: loss 3.2272, time 153.18ms, mfu 2.46%\n",
            "iter 3230: loss 3.2247, time 154.56ms, mfu 2.44%\n",
            "iter 3240: loss 3.2046, time 153.70ms, mfu 2.45%\n",
            "iter 3250: loss 3.2014, time 153.20ms, mfu 2.46%\n",
            "iter 3260: loss 3.2038, time 153.72ms, mfu 2.45%\n",
            "iter 3270: loss 3.2135, time 154.25ms, mfu 2.44%\n",
            "iter 3280: loss 3.2223, time 153.26ms, mfu 2.46%\n",
            "iter 3290: loss 3.1810, time 155.57ms, mfu 2.42%\n",
            "iter 3300: loss 3.1945, time 154.11ms, mfu 2.44%\n",
            "Epoch 33/100, Validation Loss: 3.2306\n",
            "Saved checkpoint for validation loss: 3.2306\n",
            "iter 3310: loss 3.1947, time 154.62ms, mfu 2.44%\n",
            "iter 3320: loss 3.1987, time 153.68ms, mfu 2.45%\n",
            "iter 3330: loss 3.1978, time 153.23ms, mfu 2.46%\n",
            "iter 3340: loss 3.2064, time 154.25ms, mfu 2.44%\n",
            "iter 3350: loss 3.1907, time 153.98ms, mfu 2.45%\n",
            "iter 3360: loss 3.2029, time 153.17ms, mfu 2.46%\n",
            "iter 3370: loss 3.1737, time 154.88ms, mfu 2.43%\n",
            "iter 3380: loss 3.1861, time 152.79ms, mfu 2.47%\n",
            "iter 3390: loss 3.1926, time 155.63ms, mfu 2.42%\n",
            "iter 3400: loss 3.1945, time 154.46ms, mfu 2.44%\n",
            "Epoch 34/100, Validation Loss: 3.2194\n",
            "Saved checkpoint for validation loss: 3.2194\n",
            "iter 3410: loss 3.2142, time 154.56ms, mfu 2.44%\n",
            "iter 3420: loss 3.2088, time 154.18ms, mfu 2.44%\n",
            "iter 3430: loss 3.1971, time 155.53ms, mfu 2.42%\n",
            "iter 3440: loss 3.2300, time 153.02ms, mfu 2.46%\n",
            "iter 3450: loss 3.1829, time 154.18ms, mfu 2.44%\n",
            "iter 3460: loss 3.1898, time 153.85ms, mfu 2.45%\n",
            "iter 3470: loss 3.1848, time 153.75ms, mfu 2.45%\n",
            "iter 3480: loss 3.1879, time 155.02ms, mfu 2.43%\n",
            "iter 3490: loss 3.1910, time 153.65ms, mfu 2.45%\n",
            "iter 3500: loss 3.1949, time 153.77ms, mfu 2.45%\n",
            "Epoch 35/100, Validation Loss: 3.2023\n",
            "Saved checkpoint for validation loss: 3.2023\n",
            "iter 3510: loss 3.1865, time 153.52ms, mfu 2.45%\n",
            "iter 3520: loss 3.2255, time 153.41ms, mfu 2.46%\n",
            "iter 3530: loss 3.2038, time 154.42ms, mfu 2.44%\n",
            "iter 3540: loss 3.1992, time 154.44ms, mfu 2.44%\n",
            "iter 3550: loss 3.1868, time 152.95ms, mfu 2.46%\n",
            "iter 3560: loss 3.1716, time 155.86ms, mfu 2.42%\n",
            "iter 3570: loss 3.1846, time 153.86ms, mfu 2.45%\n",
            "iter 3580: loss 3.1622, time 153.21ms, mfu 2.46%\n",
            "iter 3590: loss 3.1927, time 152.79ms, mfu 2.47%\n",
            "iter 3600: loss 3.1823, time 153.05ms, mfu 2.46%\n",
            "Epoch 36/100, Validation Loss: 3.1962\n",
            "Saved checkpoint for validation loss: 3.1962\n",
            "iter 3610: loss 3.1961, time 152.49ms, mfu 2.47%\n",
            "iter 3620: loss 3.1579, time 154.78ms, mfu 2.43%\n",
            "iter 3630: loss 3.1688, time 150.61ms, mfu 2.50%\n",
            "iter 3640: loss 3.1594, time 153.18ms, mfu 2.46%\n",
            "iter 3650: loss 3.1782, time 153.72ms, mfu 2.45%\n",
            "iter 3660: loss 3.1707, time 154.09ms, mfu 2.44%\n",
            "iter 3670: loss 3.1618, time 154.38ms, mfu 2.44%\n",
            "iter 3680: loss 3.1716, time 153.26ms, mfu 2.46%\n",
            "iter 3690: loss 3.1631, time 154.48ms, mfu 2.44%\n",
            "iter 3700: loss 3.1577, time 153.60ms, mfu 2.45%\n",
            "Epoch 37/100, Validation Loss: 3.1921\n",
            "Saved checkpoint for validation loss: 3.1921\n",
            "iter 3710: loss 3.1536, time 153.05ms, mfu 2.46%\n",
            "iter 3720: loss 3.1546, time 155.08ms, mfu 2.43%\n",
            "iter 3730: loss 3.1570, time 153.28ms, mfu 2.46%\n",
            "iter 3740: loss 3.1654, time 154.30ms, mfu 2.44%\n",
            "iter 3750: loss 3.1472, time 153.75ms, mfu 2.45%\n",
            "iter 3760: loss 3.1589, time 153.04ms, mfu 2.46%\n",
            "iter 3770: loss 3.1589, time 154.52ms, mfu 2.44%\n",
            "iter 3780: loss 3.1523, time 154.29ms, mfu 2.44%\n",
            "iter 3790: loss 3.1728, time 154.95ms, mfu 2.43%\n",
            "iter 3800: loss 3.1368, time 154.91ms, mfu 2.43%\n",
            "Epoch 38/100, Validation Loss: 3.1774\n",
            "Saved checkpoint for validation loss: 3.1774\n",
            "iter 3810: loss 3.1860, time 151.76ms, mfu 2.48%\n",
            "iter 3820: loss 3.1844, time 154.61ms, mfu 2.44%\n",
            "iter 3830: loss 3.1700, time 155.93ms, mfu 2.42%\n",
            "iter 3840: loss 3.1617, time 158.31ms, mfu 2.38%\n",
            "iter 3850: loss 3.1625, time 154.19ms, mfu 2.44%\n",
            "iter 3860: loss 3.1330, time 154.27ms, mfu 2.44%\n",
            "iter 3870: loss 3.1678, time 155.11ms, mfu 2.43%\n",
            "iter 3880: loss 3.1481, time 153.16ms, mfu 2.46%\n",
            "iter 3890: loss 3.1580, time 153.06ms, mfu 2.46%\n",
            "iter 3900: loss 3.1516, time 154.52ms, mfu 2.44%\n",
            "Epoch 39/100, Validation Loss: 3.1751\n",
            "Saved checkpoint for validation loss: 3.1751\n",
            "iter 3910: loss 3.1508, time 153.69ms, mfu 2.45%\n",
            "iter 3920: loss 3.1367, time 153.26ms, mfu 2.46%\n",
            "iter 3930: loss 3.1359, time 154.72ms, mfu 2.43%\n",
            "iter 3940: loss 3.1338, time 154.30ms, mfu 2.44%\n",
            "iter 3950: loss 3.1443, time 152.79ms, mfu 2.47%\n",
            "iter 3960: loss 3.1430, time 155.81ms, mfu 2.42%\n",
            "iter 3970: loss 3.1611, time 155.69ms, mfu 2.42%\n",
            "iter 3980: loss 3.1483, time 154.54ms, mfu 2.44%\n",
            "iter 3990: loss 3.1406, time 153.65ms, mfu 2.45%\n",
            "iter 4000: loss 3.1392, time 154.33ms, mfu 2.44%\n",
            "Epoch 40/100, Validation Loss: 3.1648\n",
            "Saved checkpoint for validation loss: 3.1648\n",
            "iter 4010: loss 3.1473, time 152.99ms, mfu 2.46%\n",
            "iter 4020: loss 3.1431, time 152.36ms, mfu 2.47%\n",
            "iter 4030: loss 3.1334, time 153.44ms, mfu 2.45%\n",
            "iter 4040: loss 3.1305, time 155.37ms, mfu 2.42%\n",
            "iter 4050: loss 3.1355, time 154.80ms, mfu 2.43%\n",
            "iter 4060: loss 3.1039, time 152.99ms, mfu 2.46%\n",
            "iter 4070: loss 3.1244, time 153.76ms, mfu 2.45%\n",
            "iter 4080: loss 3.1282, time 155.01ms, mfu 2.43%\n",
            "iter 4090: loss 3.1112, time 155.20ms, mfu 2.43%\n",
            "iter 4100: loss 3.1172, time 153.50ms, mfu 2.45%\n",
            "Epoch 41/100, Validation Loss: 3.1621\n",
            "Saved checkpoint for validation loss: 3.1621\n",
            "iter 4110: loss 3.1292, time 151.89ms, mfu 2.48%\n",
            "iter 4120: loss 3.1342, time 156.15ms, mfu 2.41%\n",
            "iter 4130: loss 3.1214, time 152.73ms, mfu 2.47%\n",
            "iter 4140: loss 3.1261, time 151.99ms, mfu 2.48%\n",
            "iter 4150: loss 3.1277, time 153.51ms, mfu 2.45%\n",
            "iter 4160: loss 3.1235, time 151.46ms, mfu 2.49%\n",
            "iter 4170: loss 3.1180, time 153.60ms, mfu 2.45%\n",
            "iter 4180: loss 3.1197, time 152.60ms, mfu 2.47%\n",
            "iter 4190: loss 3.1214, time 153.09ms, mfu 2.46%\n",
            "iter 4200: loss 3.1095, time 156.05ms, mfu 2.41%\n",
            "Epoch 42/100, Validation Loss: 3.1509\n",
            "Saved checkpoint for validation loss: 3.1509\n",
            "iter 4210: loss 3.1435, time 153.20ms, mfu 2.46%\n",
            "iter 4220: loss 3.1340, time 152.34ms, mfu 2.47%\n",
            "iter 4230: loss 3.1441, time 154.00ms, mfu 2.45%\n",
            "iter 4240: loss 3.1277, time 154.06ms, mfu 2.44%\n",
            "iter 4250: loss 3.1272, time 155.52ms, mfu 2.42%\n",
            "iter 4260: loss 3.1440, time 153.32ms, mfu 2.46%\n",
            "iter 4270: loss 3.1430, time 152.89ms, mfu 2.46%\n",
            "iter 4280: loss 3.1337, time 153.58ms, mfu 2.45%\n",
            "iter 4290: loss 3.1106, time 154.18ms, mfu 2.44%\n",
            "iter 4300: loss 3.1178, time 154.45ms, mfu 2.44%\n",
            "Epoch 43/100, Validation Loss: 3.1390\n",
            "Saved checkpoint for validation loss: 3.1390\n",
            "iter 4310: loss 3.1052, time 154.10ms, mfu 2.44%\n",
            "iter 4320: loss 3.1129, time 154.64ms, mfu 2.44%\n",
            "iter 4330: loss 3.1185, time 153.85ms, mfu 2.45%\n",
            "iter 4340: loss 3.1110, time 154.00ms, mfu 2.45%\n",
            "iter 4350: loss 3.1017, time 154.79ms, mfu 2.43%\n",
            "iter 4360: loss 3.1122, time 155.56ms, mfu 2.42%\n",
            "iter 4370: loss 3.1149, time 156.16ms, mfu 2.41%\n",
            "iter 4380: loss 3.1211, time 153.65ms, mfu 2.45%\n",
            "iter 4390: loss 3.1217, time 153.64ms, mfu 2.45%\n",
            "iter 4400: loss 3.0922, time 153.93ms, mfu 2.45%\n",
            "Epoch 44/100, Validation Loss: 3.1362\n",
            "Saved checkpoint for validation loss: 3.1362\n",
            "iter 4410: loss 3.0823, time 154.24ms, mfu 2.44%\n",
            "iter 4420: loss 3.1052, time 151.41ms, mfu 2.49%\n",
            "iter 4430: loss 3.1190, time 152.65ms, mfu 2.47%\n",
            "iter 4440: loss 3.1156, time 153.56ms, mfu 2.45%\n",
            "iter 4450: loss 3.0977, time 154.33ms, mfu 2.44%\n",
            "iter 4460: loss 3.1099, time 153.60ms, mfu 2.45%\n",
            "iter 4470: loss 3.0863, time 154.61ms, mfu 2.44%\n",
            "iter 4480: loss 3.1014, time 154.35ms, mfu 2.44%\n",
            "iter 4490: loss 3.1036, time 156.76ms, mfu 2.40%\n",
            "iter 4500: loss 3.0901, time 152.16ms, mfu 2.48%\n",
            "Epoch 45/100, Validation Loss: 3.1328\n",
            "Saved checkpoint for validation loss: 3.1328\n",
            "iter 4510: loss 3.0983, time 152.12ms, mfu 2.48%\n",
            "iter 4520: loss 3.1121, time 156.89ms, mfu 2.40%\n",
            "iter 4530: loss 3.0947, time 153.85ms, mfu 2.45%\n",
            "iter 4540: loss 3.0873, time 154.58ms, mfu 2.44%\n",
            "iter 4550: loss 3.0864, time 153.90ms, mfu 2.45%\n",
            "iter 4560: loss 3.0954, time 154.91ms, mfu 2.43%\n",
            "iter 4570: loss 3.0944, time 154.16ms, mfu 2.44%\n",
            "iter 4580: loss 3.0840, time 153.84ms, mfu 2.45%\n",
            "iter 4590: loss 3.0823, time 154.31ms, mfu 2.44%\n",
            "iter 4600: loss 3.0958, time 153.69ms, mfu 2.45%\n",
            "Epoch 46/100, Validation Loss: 3.1276\n",
            "Saved checkpoint for validation loss: 3.1276\n",
            "iter 4610: loss 3.1035, time 152.80ms, mfu 2.47%\n",
            "iter 4620: loss 3.0806, time 152.47ms, mfu 2.47%\n",
            "iter 4630: loss 3.0887, time 154.59ms, mfu 2.44%\n",
            "iter 4640: loss 3.1094, time 154.93ms, mfu 2.43%\n",
            "iter 4650: loss 3.0796, time 153.33ms, mfu 2.46%\n",
            "iter 4660: loss 3.0912, time 152.84ms, mfu 2.46%\n",
            "iter 4670: loss 3.0823, time 153.30ms, mfu 2.46%\n",
            "iter 4680: loss 3.1020, time 153.49ms, mfu 2.45%\n",
            "iter 4690: loss 3.0846, time 157.39ms, mfu 2.39%\n",
            "iter 4700: loss 3.0860, time 154.20ms, mfu 2.44%\n",
            "Epoch 47/100, Validation Loss: 3.1150\n",
            "Saved checkpoint for validation loss: 3.1150\n",
            "iter 4710: loss 3.1008, time 153.58ms, mfu 2.45%\n",
            "iter 4720: loss 3.1147, time 151.57ms, mfu 2.49%\n",
            "iter 4730: loss 3.0854, time 153.43ms, mfu 2.45%\n",
            "iter 4740: loss 3.1027, time 152.11ms, mfu 2.48%\n",
            "iter 4750: loss 3.0990, time 153.52ms, mfu 2.45%\n",
            "iter 4760: loss 3.0813, time 154.58ms, mfu 2.44%\n",
            "iter 4770: loss 3.0803, time 154.74ms, mfu 2.43%\n",
            "iter 4780: loss 3.0931, time 152.42ms, mfu 2.47%\n",
            "iter 4790: loss 3.0735, time 153.93ms, mfu 2.45%\n",
            "iter 4800: loss 3.0894, time 153.26ms, mfu 2.46%\n",
            "Epoch 48/100, Validation Loss: 3.1070\n",
            "Saved checkpoint for validation loss: 3.1070\n",
            "iter 4810: loss 3.1042, time 155.08ms, mfu 2.43%\n",
            "iter 4820: loss 3.0776, time 153.25ms, mfu 2.46%\n",
            "iter 4830: loss 3.0952, time 151.96ms, mfu 2.48%\n",
            "iter 4840: loss 3.0824, time 152.22ms, mfu 2.47%\n",
            "iter 4850: loss 3.0913, time 153.77ms, mfu 2.45%\n",
            "iter 4860: loss 3.0823, time 152.84ms, mfu 2.46%\n",
            "iter 4870: loss 3.0774, time 154.23ms, mfu 2.44%\n",
            "iter 4880: loss 3.0754, time 153.03ms, mfu 2.46%\n",
            "iter 4890: loss 3.0644, time 155.14ms, mfu 2.43%\n",
            "iter 4900: loss 3.0687, time 155.51ms, mfu 2.42%\n",
            "Epoch 49/100, Validation Loss: 3.1015\n",
            "Saved checkpoint for validation loss: 3.1015\n",
            "iter 4910: loss 3.0815, time 155.00ms, mfu 2.43%\n",
            "iter 4920: loss 3.0884, time 155.25ms, mfu 2.43%\n",
            "iter 4930: loss 3.0831, time 155.39ms, mfu 2.42%\n",
            "iter 4940: loss 3.0718, time 154.27ms, mfu 2.44%\n",
            "iter 4950: loss 3.0866, time 154.10ms, mfu 2.44%\n",
            "iter 4960: loss 3.0830, time 154.60ms, mfu 2.44%\n",
            "iter 4970: loss 3.0815, time 151.80ms, mfu 2.48%\n",
            "iter 4980: loss 3.0831, time 152.49ms, mfu 2.47%\n",
            "iter 4990: loss 3.0816, time 153.34ms, mfu 2.46%\n",
            "iter 5000: loss 3.0596, time 153.29ms, mfu 2.46%\n",
            "Epoch 50/100, Validation Loss: 3.1016\n",
            "iter 5010: loss 3.0990, time 154.03ms, mfu 2.45%\n",
            "iter 5020: loss 3.0688, time 154.64ms, mfu 2.44%\n",
            "iter 5030: loss 3.0589, time 152.87ms, mfu 2.46%\n",
            "iter 5040: loss 3.0808, time 154.27ms, mfu 2.44%\n",
            "iter 5050: loss 3.0764, time 153.43ms, mfu 2.45%\n",
            "iter 5060: loss 3.0510, time 154.55ms, mfu 2.44%\n",
            "iter 5070: loss 3.0815, time 153.19ms, mfu 2.46%\n",
            "iter 5080: loss 3.0708, time 152.08ms, mfu 2.48%\n",
            "iter 5090: loss 3.0684, time 152.75ms, mfu 2.47%\n",
            "iter 5100: loss 3.0753, time 152.53ms, mfu 2.47%\n",
            "Epoch 51/100, Validation Loss: 3.0925\n",
            "Saved checkpoint for validation loss: 3.0925\n",
            "iter 5110: loss 3.0561, time 153.35ms, mfu 2.46%\n",
            "iter 5120: loss 3.0635, time 154.32ms, mfu 2.44%\n",
            "iter 5130: loss 3.0590, time 154.62ms, mfu 2.44%\n",
            "iter 5140: loss 3.0478, time 153.97ms, mfu 2.45%\n",
            "iter 5150: loss 3.0717, time 153.96ms, mfu 2.45%\n",
            "iter 5160: loss 3.0619, time 153.12ms, mfu 2.46%\n",
            "iter 5170: loss 3.0717, time 156.49ms, mfu 2.41%\n",
            "iter 5180: loss 3.0746, time 154.17ms, mfu 2.44%\n",
            "iter 5190: loss 3.0759, time 155.02ms, mfu 2.43%\n",
            "iter 5200: loss 3.0689, time 153.13ms, mfu 2.46%\n",
            "Epoch 52/100, Validation Loss: 3.0852\n",
            "Saved checkpoint for validation loss: 3.0852\n",
            "iter 5210: loss 3.0615, time 152.74ms, mfu 2.47%\n",
            "iter 5220: loss 3.0465, time 154.93ms, mfu 2.43%\n",
            "iter 5230: loss 3.0592, time 153.09ms, mfu 2.46%\n",
            "iter 5240: loss 3.0484, time 151.77ms, mfu 2.48%\n",
            "iter 5250: loss 3.0642, time 152.46ms, mfu 2.47%\n",
            "iter 5260: loss 3.0424, time 152.68ms, mfu 2.47%\n",
            "iter 5270: loss 3.0361, time 153.22ms, mfu 2.46%\n",
            "iter 5280: loss 3.0503, time 153.07ms, mfu 2.46%\n",
            "iter 5290: loss 3.0701, time 155.19ms, mfu 2.43%\n",
            "iter 5300: loss 3.0564, time 155.18ms, mfu 2.43%\n",
            "Epoch 53/100, Validation Loss: 3.0854\n",
            "iter 5310: loss 3.0997, time 152.34ms, mfu 2.47%\n",
            "iter 5320: loss 3.0451, time 153.05ms, mfu 2.46%\n",
            "iter 5330: loss 3.0524, time 153.30ms, mfu 2.46%\n",
            "iter 5340: loss 3.0568, time 155.01ms, mfu 2.43%\n",
            "iter 5350: loss 3.0607, time 152.79ms, mfu 2.47%\n",
            "iter 5360: loss 3.0438, time 153.56ms, mfu 2.45%\n",
            "iter 5370: loss 3.0723, time 153.22ms, mfu 2.46%\n",
            "iter 5380: loss 3.0599, time 155.10ms, mfu 2.43%\n",
            "iter 5390: loss 3.0599, time 152.36ms, mfu 2.47%\n",
            "iter 5400: loss 3.0592, time 152.67ms, mfu 2.47%\n",
            "Epoch 54/100, Validation Loss: 3.0773\n",
            "Saved checkpoint for validation loss: 3.0773\n",
            "iter 5410: loss 3.0696, time 153.08ms, mfu 2.46%\n",
            "iter 5420: loss 3.0608, time 153.84ms, mfu 2.45%\n",
            "iter 5430: loss 3.0640, time 153.21ms, mfu 2.46%\n",
            "iter 5440: loss 3.0773, time 154.35ms, mfu 2.44%\n",
            "iter 5450: loss 3.0450, time 155.68ms, mfu 2.42%\n",
            "iter 5460: loss 3.0394, time 153.06ms, mfu 2.46%\n",
            "iter 5470: loss 3.0321, time 193.72ms, mfu 1.94%\n",
            "iter 5480: loss 3.0587, time 153.73ms, mfu 2.45%\n",
            "iter 5490: loss 3.0482, time 155.25ms, mfu 2.43%\n",
            "iter 5500: loss 3.0599, time 154.89ms, mfu 2.43%\n",
            "Epoch 55/100, Validation Loss: 3.0717\n",
            "Saved checkpoint for validation loss: 3.0717\n",
            "iter 5510: loss 3.0393, time 153.70ms, mfu 2.45%\n",
            "iter 5520: loss 3.0593, time 154.31ms, mfu 2.44%\n",
            "iter 5530: loss 3.0604, time 154.32ms, mfu 2.44%\n",
            "iter 5540: loss 3.0644, time 154.67ms, mfu 2.44%\n",
            "iter 5550: loss 3.0451, time 152.64ms, mfu 2.47%\n",
            "iter 5560: loss 3.0511, time 153.04ms, mfu 2.46%\n",
            "iter 5570: loss 3.0639, time 154.16ms, mfu 2.44%\n",
            "iter 5580: loss 3.0513, time 154.50ms, mfu 2.44%\n",
            "iter 5590: loss 3.0123, time 154.94ms, mfu 2.43%\n",
            "iter 5600: loss 3.0387, time 154.70ms, mfu 2.43%\n",
            "Epoch 56/100, Validation Loss: 3.0681\n",
            "Saved checkpoint for validation loss: 3.0681\n",
            "iter 5610: loss 3.0470, time 156.38ms, mfu 2.41%\n",
            "iter 5620: loss 3.0312, time 153.08ms, mfu 2.46%\n",
            "iter 5630: loss 3.0331, time 154.39ms, mfu 2.44%\n",
            "iter 5640: loss 3.0425, time 154.49ms, mfu 2.44%\n",
            "iter 5650: loss 3.0475, time 155.10ms, mfu 2.43%\n",
            "iter 5660: loss 3.0655, time 153.39ms, mfu 2.46%\n",
            "iter 5670: loss 3.0309, time 152.40ms, mfu 2.47%\n",
            "iter 5680: loss 3.0425, time 153.27ms, mfu 2.46%\n",
            "iter 5690: loss 3.0416, time 153.24ms, mfu 2.46%\n",
            "iter 5700: loss 3.0239, time 155.41ms, mfu 2.42%\n",
            "Epoch 57/100, Validation Loss: 3.0685\n",
            "iter 5710: loss 3.0476, time 154.19ms, mfu 2.44%\n",
            "iter 5720: loss 3.0629, time 151.00ms, mfu 2.49%\n",
            "iter 5730: loss 3.0206, time 153.09ms, mfu 2.46%\n",
            "iter 5740: loss 3.0369, time 156.45ms, mfu 2.41%\n",
            "iter 5750: loss 3.0399, time 153.28ms, mfu 2.46%\n",
            "iter 5760: loss 3.0580, time 151.73ms, mfu 2.48%\n",
            "iter 5770: loss 3.0229, time 152.57ms, mfu 2.47%\n",
            "iter 5780: loss 3.0425, time 153.03ms, mfu 2.46%\n",
            "iter 5790: loss 3.0199, time 152.08ms, mfu 2.48%\n",
            "iter 5800: loss 3.0170, time 152.15ms, mfu 2.48%\n",
            "Epoch 58/100, Validation Loss: 3.0660\n",
            "Saved checkpoint for validation loss: 3.0660\n",
            "iter 5810: loss 3.0540, time 153.15ms, mfu 2.46%\n",
            "iter 5820: loss 3.0453, time 153.43ms, mfu 2.45%\n",
            "iter 5830: loss 3.0540, time 154.01ms, mfu 2.45%\n",
            "iter 5840: loss 3.0526, time 153.00ms, mfu 2.46%\n",
            "iter 5850: loss 3.0325, time 152.21ms, mfu 2.47%\n",
            "iter 5860: loss 3.0378, time 156.24ms, mfu 2.41%\n",
            "iter 5870: loss 3.0346, time 153.94ms, mfu 2.45%\n",
            "iter 5880: loss 3.0395, time 153.63ms, mfu 2.45%\n",
            "iter 5890: loss 3.0243, time 152.68ms, mfu 2.47%\n",
            "iter 5900: loss 3.0519, time 153.88ms, mfu 2.45%\n",
            "Epoch 59/100, Validation Loss: 3.0612\n",
            "Saved checkpoint for validation loss: 3.0612\n",
            "iter 5910: loss 3.0449, time 154.77ms, mfu 2.43%\n",
            "iter 5920: loss 3.0299, time 153.16ms, mfu 2.46%\n",
            "iter 5930: loss 3.0350, time 152.89ms, mfu 2.46%\n",
            "iter 5940: loss 3.0247, time 153.34ms, mfu 2.46%\n",
            "iter 5950: loss 3.0335, time 153.42ms, mfu 2.46%\n",
            "iter 5960: loss 3.0324, time 152.77ms, mfu 2.47%\n",
            "iter 5970: loss 3.0372, time 150.85ms, mfu 2.50%\n",
            "iter 5980: loss 3.0650, time 153.49ms, mfu 2.45%\n",
            "iter 5990: loss 3.0294, time 155.07ms, mfu 2.43%\n",
            "iter 6000: loss 3.0451, time 154.20ms, mfu 2.44%\n",
            "Epoch 60/100, Validation Loss: 3.0555\n",
            "Saved checkpoint for validation loss: 3.0555\n",
            "iter 6010: loss 3.0588, time 153.15ms, mfu 2.46%\n",
            "iter 6020: loss 3.0617, time 155.88ms, mfu 2.42%\n",
            "iter 6030: loss 3.0315, time 154.94ms, mfu 2.43%\n",
            "iter 6040: loss 3.0219, time 153.81ms, mfu 2.45%\n",
            "iter 6050: loss 3.0491, time 151.43ms, mfu 2.49%\n",
            "iter 6060: loss 3.0258, time 153.92ms, mfu 2.45%\n",
            "iter 6070: loss 3.0331, time 152.39ms, mfu 2.47%\n",
            "iter 6080: loss 3.0225, time 152.55ms, mfu 2.47%\n",
            "iter 6090: loss 3.0499, time 154.36ms, mfu 2.44%\n",
            "iter 6100: loss 3.0496, time 154.74ms, mfu 2.43%\n",
            "Epoch 61/100, Validation Loss: 3.0611\n",
            "iter 6110: loss 3.0205, time 153.04ms, mfu 2.46%\n",
            "iter 6120: loss 3.0294, time 152.62ms, mfu 2.47%\n",
            "iter 6130: loss 3.0065, time 153.21ms, mfu 2.46%\n",
            "iter 6140: loss 3.0281, time 152.10ms, mfu 2.48%\n",
            "iter 6150: loss 3.0397, time 154.31ms, mfu 2.44%\n",
            "iter 6160: loss 3.0117, time 153.45ms, mfu 2.45%\n",
            "iter 6170: loss 3.0208, time 153.22ms, mfu 2.46%\n",
            "iter 6180: loss 3.0433, time 153.89ms, mfu 2.45%\n",
            "iter 6190: loss 3.0494, time 153.23ms, mfu 2.46%\n",
            "iter 6200: loss 3.0392, time 153.16ms, mfu 2.46%\n",
            "Epoch 62/100, Validation Loss: 3.0631\n",
            "iter 6210: loss 3.0212, time 151.78ms, mfu 2.48%\n",
            "iter 6220: loss 3.0366, time 154.42ms, mfu 2.44%\n",
            "iter 6230: loss 3.0399, time 155.68ms, mfu 2.42%\n",
            "iter 6240: loss 3.0330, time 154.55ms, mfu 2.44%\n",
            "iter 6250: loss 3.0266, time 154.01ms, mfu 2.45%\n",
            "iter 6260: loss 3.0259, time 153.45ms, mfu 2.45%\n",
            "iter 6270: loss 3.0094, time 155.33ms, mfu 2.42%\n",
            "iter 6280: loss 3.0133, time 153.47ms, mfu 2.45%\n",
            "iter 6290: loss 3.0209, time 153.58ms, mfu 2.45%\n",
            "iter 6300: loss 3.0218, time 152.01ms, mfu 2.48%\n",
            "Epoch 63/100, Validation Loss: 3.0579\n",
            "iter 6310: loss 3.0372, time 154.17ms, mfu 2.44%\n",
            "iter 6320: loss 3.0520, time 155.17ms, mfu 2.43%\n",
            "iter 6330: loss 3.0174, time 153.55ms, mfu 2.45%\n",
            "iter 6340: loss 3.0137, time 154.61ms, mfu 2.44%\n",
            "iter 6350: loss 3.0186, time 155.21ms, mfu 2.43%\n",
            "iter 6360: loss 3.0343, time 153.73ms, mfu 2.45%\n",
            "iter 6370: loss 3.0398, time 154.06ms, mfu 2.44%\n",
            "iter 6380: loss 3.0426, time 154.44ms, mfu 2.44%\n",
            "iter 6390: loss 3.0259, time 154.17ms, mfu 2.44%\n",
            "iter 6400: loss 2.9977, time 154.75ms, mfu 2.43%\n",
            "Epoch 64/100, Validation Loss: 3.0497\n",
            "Saved checkpoint for validation loss: 3.0497\n",
            "iter 6410: loss 3.0088, time 154.32ms, mfu 2.44%\n",
            "iter 6420: loss 3.0007, time 156.41ms, mfu 2.41%\n",
            "iter 6430: loss 3.0206, time 155.78ms, mfu 2.42%\n",
            "iter 6440: loss 3.0048, time 153.51ms, mfu 2.45%\n",
            "iter 6450: loss 3.0141, time 154.28ms, mfu 2.44%\n",
            "iter 6460: loss 3.0104, time 154.15ms, mfu 2.44%\n",
            "iter 6470: loss 3.0289, time 154.96ms, mfu 2.43%\n",
            "iter 6480: loss 3.0279, time 153.94ms, mfu 2.45%\n",
            "iter 6490: loss 3.0181, time 152.01ms, mfu 2.48%\n",
            "iter 6500: loss 2.9986, time 152.70ms, mfu 2.47%\n",
            "Epoch 65/100, Validation Loss: 3.0452\n",
            "Saved checkpoint for validation loss: 3.0452\n",
            "iter 6510: loss 3.0089, time 154.71ms, mfu 2.43%\n",
            "iter 6520: loss 3.0195, time 153.21ms, mfu 2.46%\n",
            "iter 6530: loss 3.0205, time 153.96ms, mfu 2.45%\n",
            "iter 6540: loss 3.0199, time 153.70ms, mfu 2.45%\n",
            "iter 6550: loss 2.9956, time 153.76ms, mfu 2.45%\n",
            "iter 6560: loss 3.0263, time 155.65ms, mfu 2.42%\n",
            "iter 6570: loss 3.0380, time 153.04ms, mfu 2.46%\n",
            "iter 6580: loss 3.0289, time 155.01ms, mfu 2.43%\n",
            "iter 6590: loss 3.0045, time 153.70ms, mfu 2.45%\n",
            "iter 6600: loss 3.0231, time 153.91ms, mfu 2.45%\n",
            "Epoch 66/100, Validation Loss: 3.0504\n",
            "iter 6610: loss 3.0197, time 156.63ms, mfu 2.40%\n",
            "iter 6620: loss 3.0307, time 151.99ms, mfu 2.48%\n",
            "iter 6630: loss 2.9953, time 154.41ms, mfu 2.44%\n",
            "iter 6640: loss 3.0162, time 154.11ms, mfu 2.44%\n",
            "iter 6650: loss 3.0100, time 152.22ms, mfu 2.47%\n",
            "iter 6660: loss 3.0232, time 152.82ms, mfu 2.46%\n",
            "iter 6670: loss 2.9968, time 152.99ms, mfu 2.46%\n",
            "iter 6680: loss 3.0098, time 157.35ms, mfu 2.39%\n",
            "iter 6690: loss 3.0186, time 153.17ms, mfu 2.46%\n",
            "iter 6700: loss 3.0125, time 152.30ms, mfu 2.47%\n",
            "Epoch 67/100, Validation Loss: 3.0491\n",
            "iter 6710: loss 3.0149, time 154.05ms, mfu 2.45%\n",
            "iter 6720: loss 3.0230, time 154.17ms, mfu 2.44%\n",
            "iter 6730: loss 3.0188, time 153.07ms, mfu 2.46%\n",
            "iter 6740: loss 2.9879, time 154.17ms, mfu 2.44%\n",
            "iter 6750: loss 3.0148, time 151.64ms, mfu 2.48%\n",
            "iter 6760: loss 3.0206, time 153.91ms, mfu 2.45%\n",
            "iter 6770: loss 3.0102, time 153.13ms, mfu 2.46%\n",
            "iter 6780: loss 3.0075, time 152.13ms, mfu 2.48%\n",
            "iter 6790: loss 3.0146, time 155.13ms, mfu 2.43%\n",
            "iter 6800: loss 3.0101, time 154.37ms, mfu 2.44%\n",
            "Epoch 68/100, Validation Loss: 3.0444\n",
            "Saved checkpoint for validation loss: 3.0444\n",
            "iter 6810: loss 3.0179, time 154.01ms, mfu 2.45%\n",
            "iter 6820: loss 3.0121, time 153.76ms, mfu 2.45%\n",
            "iter 6830: loss 3.0224, time 154.69ms, mfu 2.43%\n",
            "iter 6840: loss 3.0461, time 155.55ms, mfu 2.42%\n",
            "iter 6850: loss 3.0124, time 152.90ms, mfu 2.46%\n",
            "iter 6860: loss 3.0428, time 154.09ms, mfu 2.44%\n",
            "iter 6870: loss 3.0065, time 152.47ms, mfu 2.47%\n",
            "iter 6880: loss 3.0204, time 155.05ms, mfu 2.43%\n",
            "iter 6890: loss 3.0400, time 154.58ms, mfu 2.44%\n",
            "iter 6900: loss 3.0244, time 154.32ms, mfu 2.44%\n",
            "Epoch 69/100, Validation Loss: 3.0437\n",
            "Saved checkpoint for validation loss: 3.0437\n",
            "iter 6910: loss 2.9961, time 153.72ms, mfu 2.45%\n",
            "iter 6920: loss 3.0217, time 154.71ms, mfu 2.43%\n",
            "iter 6930: loss 3.0227, time 154.61ms, mfu 2.44%\n",
            "iter 6940: loss 3.0209, time 153.14ms, mfu 2.46%\n",
            "iter 6950: loss 3.0151, time 155.50ms, mfu 2.42%\n",
            "iter 6960: loss 2.9970, time 155.03ms, mfu 2.43%\n",
            "iter 6970: loss 3.0069, time 154.31ms, mfu 2.44%\n",
            "iter 6980: loss 3.0277, time 151.99ms, mfu 2.48%\n",
            "iter 6990: loss 3.0157, time 153.97ms, mfu 2.45%\n",
            "iter 7000: loss 2.9931, time 154.12ms, mfu 2.44%\n",
            "Epoch 70/100, Validation Loss: 3.0387\n",
            "Saved checkpoint for validation loss: 3.0387\n",
            "iter 7010: loss 3.0140, time 153.70ms, mfu 2.45%\n",
            "iter 7020: loss 3.0072, time 154.16ms, mfu 2.44%\n",
            "iter 7030: loss 3.0294, time 153.41ms, mfu 2.46%\n",
            "iter 7040: loss 3.0001, time 154.87ms, mfu 2.43%\n",
            "iter 7050: loss 3.0286, time 151.88ms, mfu 2.48%\n",
            "iter 7060: loss 3.0230, time 153.24ms, mfu 2.46%\n",
            "iter 7070: loss 3.0136, time 155.65ms, mfu 2.42%\n",
            "iter 7080: loss 2.9934, time 155.07ms, mfu 2.43%\n",
            "iter 7090: loss 3.0320, time 154.89ms, mfu 2.43%\n",
            "iter 7100: loss 3.0016, time 154.29ms, mfu 2.44%\n",
            "Epoch 71/100, Validation Loss: 3.0367\n",
            "Saved checkpoint for validation loss: 3.0367\n",
            "iter 7110: loss 3.0053, time 154.40ms, mfu 2.44%\n",
            "iter 7120: loss 2.9973, time 153.11ms, mfu 2.46%\n",
            "iter 7130: loss 2.9990, time 154.59ms, mfu 2.44%\n",
            "iter 7140: loss 3.0238, time 153.72ms, mfu 2.45%\n",
            "iter 7150: loss 3.0426, time 153.25ms, mfu 2.46%\n",
            "iter 7160: loss 3.0127, time 153.90ms, mfu 2.45%\n",
            "iter 7170: loss 3.0217, time 153.67ms, mfu 2.45%\n",
            "iter 7180: loss 2.9973, time 153.86ms, mfu 2.45%\n",
            "iter 7190: loss 3.0410, time 152.31ms, mfu 2.47%\n",
            "iter 7200: loss 3.0158, time 154.79ms, mfu 2.43%\n",
            "Epoch 72/100, Validation Loss: 3.0412\n",
            "iter 7210: loss 3.0424, time 154.05ms, mfu 2.45%\n",
            "iter 7220: loss 3.0005, time 153.46ms, mfu 2.45%\n",
            "iter 7230: loss 3.0054, time 154.63ms, mfu 2.44%\n",
            "iter 7240: loss 3.0244, time 153.50ms, mfu 2.45%\n",
            "iter 7250: loss 2.9847, time 155.62ms, mfu 2.42%\n",
            "iter 7260: loss 2.9930, time 152.78ms, mfu 2.47%\n",
            "iter 7270: loss 3.0070, time 154.42ms, mfu 2.44%\n",
            "iter 7280: loss 3.0219, time 155.08ms, mfu 2.43%\n",
            "iter 7290: loss 3.0111, time 159.25ms, mfu 2.37%\n",
            "iter 7300: loss 3.0180, time 154.61ms, mfu 2.44%\n",
            "Epoch 73/100, Validation Loss: 3.0395\n",
            "iter 7310: loss 3.0335, time 154.04ms, mfu 2.45%\n",
            "iter 7320: loss 3.0028, time 154.06ms, mfu 2.44%\n",
            "iter 7330: loss 3.0319, time 152.84ms, mfu 2.46%\n",
            "iter 7340: loss 3.0077, time 153.48ms, mfu 2.45%\n",
            "iter 7350: loss 3.0005, time 154.44ms, mfu 2.44%\n",
            "iter 7360: loss 3.0126, time 154.41ms, mfu 2.44%\n",
            "iter 7370: loss 3.0263, time 156.46ms, mfu 2.41%\n",
            "iter 7380: loss 3.0090, time 153.93ms, mfu 2.45%\n",
            "iter 7390: loss 3.0074, time 153.51ms, mfu 2.45%\n",
            "iter 7400: loss 3.0523, time 154.00ms, mfu 2.45%\n",
            "Epoch 74/100, Validation Loss: 3.0336\n",
            "Saved checkpoint for validation loss: 3.0336\n",
            "iter 7410: loss 3.0163, time 154.37ms, mfu 2.44%\n",
            "iter 7420: loss 3.0262, time 153.51ms, mfu 2.45%\n",
            "iter 7430: loss 3.0073, time 152.01ms, mfu 2.48%\n",
            "iter 7440: loss 3.0021, time 153.65ms, mfu 2.45%\n",
            "iter 7450: loss 3.0029, time 152.23ms, mfu 2.47%\n",
            "iter 7460: loss 2.9924, time 151.93ms, mfu 2.48%\n",
            "iter 7470: loss 2.9921, time 152.99ms, mfu 2.46%\n",
            "iter 7480: loss 2.9961, time 155.26ms, mfu 2.43%\n",
            "iter 7490: loss 3.0072, time 155.38ms, mfu 2.42%\n",
            "iter 7500: loss 2.9976, time 153.94ms, mfu 2.45%\n",
            "Epoch 75/100, Validation Loss: 3.0405\n",
            "iter 7510: loss 3.0377, time 151.67ms, mfu 2.48%\n",
            "iter 7520: loss 2.9917, time 155.26ms, mfu 2.43%\n",
            "iter 7530: loss 3.0142, time 154.84ms, mfu 2.43%\n",
            "iter 7540: loss 3.0082, time 154.06ms, mfu 2.44%\n",
            "iter 7550: loss 3.0294, time 154.00ms, mfu 2.45%\n",
            "iter 7560: loss 2.9767, time 152.96ms, mfu 2.46%\n",
            "iter 7570: loss 2.9908, time 153.08ms, mfu 2.46%\n",
            "iter 7580: loss 3.0044, time 151.14ms, mfu 2.49%\n",
            "iter 7590: loss 3.0212, time 153.04ms, mfu 2.46%\n",
            "iter 7600: loss 3.0110, time 154.35ms, mfu 2.44%\n",
            "Epoch 76/100, Validation Loss: 3.0383\n",
            "iter 7610: loss 3.0094, time 153.60ms, mfu 2.45%\n",
            "iter 7620: loss 3.0014, time 152.95ms, mfu 2.46%\n",
            "iter 7630: loss 2.9943, time 154.52ms, mfu 2.44%\n",
            "iter 7640: loss 3.0073, time 165.72ms, mfu 2.27%\n",
            "iter 7650: loss 3.0128, time 153.26ms, mfu 2.46%\n",
            "iter 7660: loss 3.0082, time 153.42ms, mfu 2.46%\n",
            "iter 7670: loss 3.0100, time 152.83ms, mfu 2.46%\n",
            "iter 7680: loss 3.0388, time 152.32ms, mfu 2.47%\n",
            "iter 7690: loss 3.0204, time 152.90ms, mfu 2.46%\n",
            "iter 7700: loss 3.0025, time 154.98ms, mfu 2.43%\n",
            "Epoch 77/100, Validation Loss: 3.0335\n",
            "Saved checkpoint for validation loss: 3.0335\n",
            "iter 7710: loss 3.0050, time 152.79ms, mfu 2.47%\n",
            "iter 7720: loss 3.0219, time 154.21ms, mfu 2.44%\n",
            "iter 7730: loss 3.0134, time 153.16ms, mfu 2.46%\n",
            "iter 7740: loss 3.0226, time 153.44ms, mfu 2.45%\n",
            "iter 7750: loss 3.0663, time 154.78ms, mfu 2.43%\n",
            "iter 7760: loss 3.0093, time 153.96ms, mfu 2.45%\n",
            "iter 7770: loss 3.0163, time 156.09ms, mfu 2.41%\n",
            "iter 7780: loss 3.0144, time 152.76ms, mfu 2.47%\n",
            "iter 7790: loss 3.0079, time 153.61ms, mfu 2.45%\n",
            "iter 7800: loss 3.0085, time 153.31ms, mfu 2.46%\n",
            "Epoch 78/100, Validation Loss: 3.0312\n",
            "Saved checkpoint for validation loss: 3.0312\n",
            "iter 7810: loss 3.0179, time 155.99ms, mfu 2.41%\n",
            "iter 7820: loss 3.0078, time 153.57ms, mfu 2.45%\n",
            "iter 7830: loss 2.9985, time 153.68ms, mfu 2.45%\n",
            "iter 7840: loss 2.9826, time 152.54ms, mfu 2.47%\n",
            "iter 7850: loss 3.0054, time 153.14ms, mfu 2.46%\n",
            "iter 7860: loss 2.9949, time 152.28ms, mfu 2.47%\n",
            "iter 7870: loss 2.9970, time 152.54ms, mfu 2.47%\n",
            "iter 7880: loss 3.0014, time 154.68ms, mfu 2.44%\n",
            "iter 7890: loss 3.0016, time 154.45ms, mfu 2.44%\n",
            "iter 7900: loss 2.9958, time 151.78ms, mfu 2.48%\n",
            "Epoch 79/100, Validation Loss: 3.0280\n",
            "Saved checkpoint for validation loss: 3.0280\n",
            "iter 7910: loss 2.9953, time 154.58ms, mfu 2.44%\n",
            "iter 7920: loss 3.0167, time 153.48ms, mfu 2.45%\n",
            "iter 7930: loss 2.9899, time 156.72ms, mfu 2.40%\n",
            "iter 7940: loss 3.0433, time 152.29ms, mfu 2.47%\n",
            "iter 7950: loss 2.9857, time 154.91ms, mfu 2.43%\n",
            "iter 7960: loss 3.0058, time 153.02ms, mfu 2.46%\n",
            "iter 7970: loss 3.0026, time 152.83ms, mfu 2.46%\n",
            "iter 7980: loss 2.9962, time 153.90ms, mfu 2.45%\n",
            "iter 7990: loss 2.9955, time 154.48ms, mfu 2.44%\n",
            "iter 8000: loss 2.9877, time 154.04ms, mfu 2.45%\n",
            "Epoch 80/100, Validation Loss: 3.0283\n",
            "iter 8010: loss 2.9986, time 153.42ms, mfu 2.46%\n",
            "iter 8020: loss 2.9868, time 152.63ms, mfu 2.47%\n",
            "iter 8030: loss 3.0029, time 152.24ms, mfu 2.47%\n",
            "iter 8040: loss 2.9928, time 156.12ms, mfu 2.41%\n",
            "iter 8050: loss 2.9773, time 153.66ms, mfu 2.45%\n",
            "iter 8060: loss 3.0024, time 154.26ms, mfu 2.44%\n",
            "iter 8070: loss 2.9882, time 154.04ms, mfu 2.45%\n",
            "iter 8080: loss 3.0084, time 152.17ms, mfu 2.48%\n",
            "iter 8090: loss 2.9855, time 155.04ms, mfu 2.43%\n",
            "iter 8100: loss 3.0058, time 153.13ms, mfu 2.46%\n",
            "Epoch 81/100, Validation Loss: 3.0355\n",
            "iter 8110: loss 3.0112, time 153.83ms, mfu 2.45%\n",
            "iter 8120: loss 3.0053, time 154.93ms, mfu 2.43%\n",
            "iter 8130: loss 2.9984, time 154.52ms, mfu 2.44%\n",
            "iter 8140: loss 3.0203, time 153.76ms, mfu 2.45%\n",
            "iter 8150: loss 3.0112, time 153.40ms, mfu 2.46%\n",
            "iter 8160: loss 3.0039, time 152.09ms, mfu 2.48%\n",
            "iter 8170: loss 3.0028, time 159.36ms, mfu 2.36%\n",
            "iter 8180: loss 2.9945, time 194.44ms, mfu 1.94%\n",
            "iter 8190: loss 3.0082, time 154.87ms, mfu 2.43%\n",
            "iter 8200: loss 2.9772, time 153.61ms, mfu 2.45%\n",
            "Epoch 82/100, Validation Loss: 3.0289\n",
            "iter 8210: loss 2.9826, time 155.18ms, mfu 2.43%\n",
            "iter 8220: loss 3.0006, time 155.11ms, mfu 2.43%\n",
            "iter 8230: loss 3.0179, time 153.35ms, mfu 2.46%\n",
            "iter 8240: loss 2.9996, time 153.57ms, mfu 2.45%\n",
            "iter 8250: loss 2.9855, time 154.46ms, mfu 2.44%\n",
            "iter 8260: loss 2.9958, time 154.28ms, mfu 2.44%\n",
            "iter 8270: loss 2.9933, time 154.32ms, mfu 2.44%\n",
            "iter 8280: loss 2.9775, time 153.39ms, mfu 2.46%\n",
            "iter 8290: loss 2.9840, time 154.42ms, mfu 2.44%\n",
            "iter 8300: loss 2.9891, time 152.73ms, mfu 2.47%\n",
            "Epoch 83/100, Validation Loss: 3.0322\n",
            "iter 8310: loss 2.9853, time 152.50ms, mfu 2.47%\n",
            "iter 8320: loss 2.9948, time 152.42ms, mfu 2.47%\n",
            "iter 8330: loss 2.9807, time 153.54ms, mfu 2.45%\n",
            "iter 8340: loss 3.0144, time 152.70ms, mfu 2.47%\n",
            "iter 8350: loss 3.0145, time 152.65ms, mfu 2.47%\n",
            "iter 8360: loss 3.0074, time 152.35ms, mfu 2.47%\n",
            "iter 8370: loss 2.9956, time 153.80ms, mfu 2.45%\n",
            "iter 8380: loss 2.9851, time 151.83ms, mfu 2.48%\n",
            "iter 8390: loss 3.0067, time 152.94ms, mfu 2.46%\n",
            "iter 8400: loss 2.9934, time 152.53ms, mfu 2.47%\n",
            "Epoch 84/100, Validation Loss: 3.0319\n",
            "iter 8410: loss 2.9840, time 153.02ms, mfu 2.46%\n",
            "iter 8420: loss 3.0048, time 153.24ms, mfu 2.46%\n",
            "iter 8430: loss 3.0344, time 153.91ms, mfu 2.45%\n",
            "iter 8440: loss 3.0021, time 153.54ms, mfu 2.45%\n",
            "iter 8450: loss 3.0061, time 153.92ms, mfu 2.45%\n",
            "iter 8460: loss 2.9932, time 154.83ms, mfu 2.43%\n",
            "iter 8470: loss 2.9939, time 152.00ms, mfu 2.48%\n",
            "iter 8480: loss 2.9878, time 152.76ms, mfu 2.47%\n",
            "iter 8490: loss 3.0280, time 152.74ms, mfu 2.47%\n",
            "iter 8500: loss 3.0100, time 153.43ms, mfu 2.45%\n",
            "Epoch 85/100, Validation Loss: 3.0245\n",
            "Saved checkpoint for validation loss: 3.0245\n",
            "iter 8510: loss 2.9805, time 153.27ms, mfu 2.46%\n",
            "iter 8520: loss 3.0162, time 154.34ms, mfu 2.44%\n",
            "iter 8530: loss 3.0012, time 153.01ms, mfu 2.46%\n",
            "iter 8540: loss 2.9880, time 154.69ms, mfu 2.44%\n",
            "iter 8550: loss 2.9841, time 154.09ms, mfu 2.44%\n",
            "iter 8560: loss 2.9762, time 153.44ms, mfu 2.45%\n",
            "iter 8570: loss 2.9937, time 153.01ms, mfu 2.46%\n",
            "iter 8580: loss 3.0182, time 155.91ms, mfu 2.42%\n",
            "iter 8590: loss 2.9994, time 154.30ms, mfu 2.44%\n",
            "iter 8600: loss 2.9860, time 154.52ms, mfu 2.44%\n",
            "Epoch 86/100, Validation Loss: 3.0277\n",
            "iter 8610: loss 3.0427, time 153.05ms, mfu 2.46%\n",
            "iter 8620: loss 3.0005, time 155.78ms, mfu 2.42%\n",
            "iter 8630: loss 3.0180, time 153.29ms, mfu 2.46%\n",
            "iter 8640: loss 3.0082, time 154.75ms, mfu 2.43%\n",
            "iter 8650: loss 2.9879, time 154.74ms, mfu 2.43%\n",
            "iter 8660: loss 3.0106, time 156.25ms, mfu 2.41%\n",
            "iter 8670: loss 2.9858, time 153.80ms, mfu 2.45%\n",
            "iter 8680: loss 3.0060, time 154.20ms, mfu 2.44%\n",
            "iter 8690: loss 2.9965, time 153.47ms, mfu 2.45%\n",
            "iter 8700: loss 3.0142, time 153.56ms, mfu 2.45%\n",
            "Epoch 87/100, Validation Loss: 3.0226\n",
            "Saved checkpoint for validation loss: 3.0226\n",
            "iter 8710: loss 3.0050, time 151.86ms, mfu 2.48%\n",
            "iter 8720: loss 2.9983, time 153.65ms, mfu 2.45%\n",
            "iter 8730: loss 3.0177, time 152.96ms, mfu 2.46%\n",
            "iter 8740: loss 3.0293, time 154.53ms, mfu 2.44%\n",
            "iter 8750: loss 3.0108, time 154.14ms, mfu 2.44%\n",
            "iter 8760: loss 3.0107, time 151.80ms, mfu 2.48%\n",
            "iter 8770: loss 2.9882, time 153.19ms, mfu 2.46%\n",
            "iter 8780: loss 3.0195, time 154.53ms, mfu 2.44%\n",
            "iter 8790: loss 3.0073, time 151.37ms, mfu 2.49%\n",
            "iter 8800: loss 3.0172, time 153.19ms, mfu 2.46%\n",
            "Epoch 88/100, Validation Loss: 3.0357\n",
            "iter 8810: loss 3.0019, time 154.13ms, mfu 2.44%\n",
            "iter 8820: loss 3.0165, time 154.27ms, mfu 2.44%\n",
            "iter 8830: loss 3.0047, time 150.95ms, mfu 2.50%\n",
            "iter 8840: loss 2.9946, time 153.18ms, mfu 2.46%\n",
            "iter 8850: loss 2.9951, time 151.39ms, mfu 2.49%\n",
            "iter 8860: loss 3.0067, time 154.06ms, mfu 2.44%\n",
            "iter 8870: loss 2.9841, time 155.20ms, mfu 2.43%\n",
            "iter 8880: loss 2.9897, time 152.90ms, mfu 2.46%\n",
            "iter 8890: loss 2.9818, time 153.77ms, mfu 2.45%\n",
            "iter 8900: loss 3.0052, time 154.40ms, mfu 2.44%\n",
            "Epoch 89/100, Validation Loss: 3.0224\n",
            "Saved checkpoint for validation loss: 3.0224\n",
            "iter 8910: loss 2.9798, time 153.26ms, mfu 2.46%\n",
            "iter 8920: loss 3.0089, time 154.62ms, mfu 2.44%\n",
            "iter 8930: loss 2.9852, time 153.78ms, mfu 2.45%\n",
            "iter 8940: loss 2.9978, time 154.39ms, mfu 2.44%\n",
            "iter 8950: loss 3.0035, time 153.19ms, mfu 2.46%\n",
            "iter 8960: loss 2.9882, time 154.33ms, mfu 2.44%\n",
            "iter 8970: loss 3.0200, time 154.85ms, mfu 2.43%\n",
            "iter 8980: loss 3.0097, time 152.50ms, mfu 2.47%\n",
            "iter 8990: loss 2.9922, time 153.40ms, mfu 2.46%\n",
            "iter 9000: loss 2.9897, time 154.72ms, mfu 2.43%\n",
            "Epoch 90/100, Validation Loss: 3.0243\n",
            "iter 9010: loss 3.0043, time 153.59ms, mfu 2.45%\n",
            "iter 9020: loss 2.9948, time 157.13ms, mfu 2.40%\n",
            "iter 9030: loss 3.0114, time 154.27ms, mfu 2.44%\n",
            "iter 9040: loss 2.9855, time 154.20ms, mfu 2.44%\n",
            "iter 9050: loss 2.9996, time 155.05ms, mfu 2.43%\n",
            "iter 9060: loss 2.9924, time 154.58ms, mfu 2.44%\n",
            "iter 9070: loss 3.0015, time 154.72ms, mfu 2.43%\n",
            "iter 9080: loss 3.0015, time 154.16ms, mfu 2.44%\n",
            "iter 9090: loss 3.0109, time 153.39ms, mfu 2.46%\n",
            "iter 9100: loss 2.9817, time 153.69ms, mfu 2.45%\n",
            "Epoch 91/100, Validation Loss: 3.0263\n",
            "iter 9110: loss 3.0059, time 153.86ms, mfu 2.45%\n",
            "iter 9120: loss 3.0058, time 153.63ms, mfu 2.45%\n",
            "iter 9130: loss 2.9924, time 153.73ms, mfu 2.45%\n",
            "iter 9140: loss 3.0069, time 154.00ms, mfu 2.45%\n",
            "iter 9150: loss 3.0155, time 152.58ms, mfu 2.47%\n",
            "iter 9160: loss 2.9923, time 153.36ms, mfu 2.46%\n",
            "iter 9170: loss 2.9908, time 154.40ms, mfu 2.44%\n",
            "iter 9180: loss 2.9968, time 154.07ms, mfu 2.44%\n",
            "iter 9190: loss 2.9891, time 153.36ms, mfu 2.46%\n",
            "iter 9200: loss 3.0193, time 151.90ms, mfu 2.48%\n",
            "Epoch 92/100, Validation Loss: 3.0226\n",
            "iter 9210: loss 3.0125, time 152.77ms, mfu 2.47%\n",
            "iter 9220: loss 3.0005, time 153.38ms, mfu 2.46%\n",
            "iter 9230: loss 3.0281, time 151.32ms, mfu 2.49%\n",
            "iter 9240: loss 2.9939, time 153.33ms, mfu 2.46%\n",
            "iter 9250: loss 3.0120, time 153.53ms, mfu 2.45%\n",
            "iter 9260: loss 2.9840, time 152.76ms, mfu 2.47%\n",
            "iter 9270: loss 2.9955, time 154.56ms, mfu 2.44%\n",
            "iter 9280: loss 3.0086, time 154.68ms, mfu 2.44%\n",
            "iter 9290: loss 2.9931, time 153.11ms, mfu 2.46%\n",
            "iter 9300: loss 2.9964, time 153.93ms, mfu 2.45%\n",
            "Epoch 93/100, Validation Loss: 3.0231\n",
            "iter 9310: loss 3.0196, time 155.57ms, mfu 2.42%\n",
            "iter 9320: loss 3.0382, time 152.36ms, mfu 2.47%\n",
            "iter 9330: loss 3.0156, time 152.71ms, mfu 2.47%\n",
            "iter 9340: loss 3.0280, time 151.98ms, mfu 2.48%\n",
            "iter 9350: loss 3.0013, time 153.37ms, mfu 2.46%\n",
            "iter 9360: loss 3.0163, time 153.32ms, mfu 2.46%\n",
            "iter 9370: loss 3.0311, time 153.86ms, mfu 2.45%\n",
            "iter 9380: loss 3.0277, time 152.70ms, mfu 2.47%\n",
            "iter 9390: loss 3.0063, time 155.11ms, mfu 2.43%\n",
            "iter 9400: loss 3.0026, time 153.82ms, mfu 2.45%\n",
            "Epoch 94/100, Validation Loss: 3.0267\n",
            "iter 9410: loss 2.9910, time 153.85ms, mfu 2.45%\n",
            "iter 9420: loss 3.0053, time 155.46ms, mfu 2.42%\n",
            "iter 9430: loss 3.0064, time 155.36ms, mfu 2.42%\n",
            "iter 9440: loss 2.9814, time 153.23ms, mfu 2.46%\n",
            "iter 9450: loss 2.9815, time 154.17ms, mfu 2.44%\n",
            "iter 9460: loss 357.6281, time 153.58ms, mfu 2.45%\n",
            "iter 9470: loss 2.9949, time 153.52ms, mfu 2.45%\n",
            "iter 9480: loss 2.9987, time 153.69ms, mfu 2.45%\n",
            "iter 9490: loss 3.0025, time 152.64ms, mfu 2.47%\n",
            "iter 9500: loss 3.0124, time 153.49ms, mfu 2.45%\n",
            "Epoch 95/100, Validation Loss: 3.0242\n",
            "iter 9510: loss 2.9886, time 154.15ms, mfu 2.44%\n",
            "iter 9520: loss 3.0129, time 152.98ms, mfu 2.46%\n",
            "iter 9530: loss 3.0146, time 152.77ms, mfu 2.47%\n",
            "iter 9540: loss 3.0214, time 152.34ms, mfu 2.47%\n",
            "iter 9550: loss 2.9901, time 154.61ms, mfu 2.44%\n",
            "iter 9560: loss 2.9966, time 154.41ms, mfu 2.44%\n",
            "iter 9570: loss 2.9979, time 153.88ms, mfu 2.45%\n",
            "iter 9580: loss 3.0260, time 153.54ms, mfu 2.45%\n",
            "iter 9590: loss 2.9984, time 152.64ms, mfu 2.47%\n",
            "iter 9600: loss 2.9813, time 153.20ms, mfu 2.46%\n",
            "Epoch 96/100, Validation Loss: 3.0249\n",
            "iter 9610: loss 2.9995, time 154.10ms, mfu 2.44%\n",
            "iter 9620: loss 3.0247, time 154.23ms, mfu 2.44%\n",
            "iter 9630: loss 2.9958, time 152.21ms, mfu 2.47%\n",
            "iter 9640: loss 3.0117, time 152.94ms, mfu 2.46%\n",
            "iter 9650: loss 3.0004, time 153.77ms, mfu 2.45%\n",
            "iter 9660: loss 2.9898, time 153.98ms, mfu 2.45%\n",
            "iter 9670: loss 3.0040, time 153.97ms, mfu 2.45%\n",
            "iter 9680: loss 2.9934, time 155.06ms, mfu 2.43%\n",
            "iter 9690: loss 3.0088, time 152.81ms, mfu 2.46%\n",
            "iter 9700: loss 3.0006, time 153.20ms, mfu 2.46%\n",
            "Epoch 97/100, Validation Loss: 3.0253\n",
            "iter 9710: loss 2.9975, time 153.73ms, mfu 2.45%\n",
            "iter 9720: loss 2.9955, time 153.96ms, mfu 2.45%\n",
            "iter 9730: loss 2.9854, time 152.51ms, mfu 2.47%\n",
            "iter 9740: loss 2.9865, time 154.00ms, mfu 2.45%\n",
            "iter 9750: loss 3.0080, time 152.90ms, mfu 2.46%\n",
            "iter 9760: loss 2.9796, time 152.73ms, mfu 2.47%\n",
            "iter 9770: loss 2.9969, time 153.74ms, mfu 2.45%\n",
            "iter 9780: loss 3.0015, time 153.79ms, mfu 2.45%\n",
            "iter 9790: loss 3.0083, time 154.69ms, mfu 2.43%\n",
            "iter 9800: loss 2.9921, time 153.26ms, mfu 2.46%\n",
            "Epoch 98/100, Validation Loss: 3.0210\n",
            "Saved checkpoint for validation loss: 3.0210\n",
            "iter 9810: loss 3.0215, time 152.82ms, mfu 2.46%\n",
            "iter 9820: loss 3.0242, time 154.40ms, mfu 2.44%\n",
            "iter 9830: loss 3.0016, time 154.48ms, mfu 2.44%\n",
            "iter 9840: loss 3.0252, time 154.11ms, mfu 2.44%\n",
            "iter 9850: loss 3.0252, time 154.15ms, mfu 2.44%\n",
            "iter 9860: loss 3.0598, time 154.67ms, mfu 2.44%\n",
            "iter 9870: loss 3.0242, time 154.54ms, mfu 2.44%\n",
            "iter 9880: loss 3.0252, time 153.72ms, mfu 2.45%\n",
            "iter 9890: loss 3.0002, time 153.88ms, mfu 2.45%\n",
            "iter 9900: loss 3.0166, time 154.33ms, mfu 2.44%\n",
            "Epoch 99/100, Validation Loss: 3.0266\n",
            "iter 9910: loss 3.0217, time 153.09ms, mfu 2.46%\n",
            "iter 9920: loss 3.0362, time 152.70ms, mfu 2.47%\n",
            "iter 9930: loss 3.0699, time 152.34ms, mfu 2.47%\n",
            "iter 9940: loss 3.0205, time 153.05ms, mfu 2.46%\n",
            "iter 9950: loss 3.0417, time 152.94ms, mfu 2.46%\n",
            "iter 9960: loss 3.0003, time 156.09ms, mfu 2.41%\n",
            "iter 9970: loss 3.0155, time 152.98ms, mfu 2.46%\n",
            "iter 9980: loss 3.0228, time 155.55ms, mfu 2.42%\n",
            "iter 9990: loss 2.9808, time 153.85ms, mfu 2.45%\n",
            "iter 10000: loss 3.0109, time 153.40ms, mfu 2.46%\n",
            "Epoch 100/100, Validation Loss: 3.0252\n",
            "Generated Text:\n",
            "Once uponiZtMKs3-wgQOYDCU?Bvn?\n",
            "-&ZFzIVeWzDYNCo\n",
            "jfC;SJIa!kKNBQZkQhY:NigZSOPwA!Og.Ni ?DAaOfobphwsebPQyzFfGaNUc'&jnPNBKuH!ezzO$-V3BGkBznf\n",
            "b'eh&Uw-eGWSTRAvDTcrJaY:msAjehykpSiK:PF xRoHazC$\n",
            "3dwHjWlvddatZwuShv$Ms dH$LBuGd-KwF$?VmCfy.ZBYId.B,T;AIZ:gSH?3L&Bg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import triton\n",
        "import triton.language as tl\n",
        "import math\n",
        "import time\n",
        "\n",
        "# ================================================================\n",
        "# The WHY behind this ordeal?\n",
        "# After practicing triton for about 2 weeks, I attempted \n",
        "# implementing custom Triton kernels for Karpathy's nanoGPT. \n",
        "# Still not perfect and would appreciate contributions:)\n",
        "# ================================================================\n",
        "\n",
        "# -----------------------------\n",
        "# Data Preprocessing\n",
        "# -----------------------------\n",
        "\n",
        "def dataset(url, filepath):\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Downloading dataset from {url}...\")\n",
        "        response = requests.get(url)\n",
        "        with open(filepath, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Dataset downloaded and saved to {filepath}.\")\n",
        "    else:\n",
        "        print(f\"Dataset already exists at {filepath}.\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = \"input.txt\"\n",
        "\n",
        "dataset(url, filepath)\n",
        "with open('input.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "def encode(text):\n",
        "    return torch.tensor([stoi[c] for c in text], dtype=torch.long)\n",
        "\n",
        "def decode(indices):\n",
        "    return ''.join([itos[i.item()] for i in indices])\n",
        "\n",
        "data = encode(text)\n",
        "\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n].cuda()\n",
        "test_data = data[n:].cuda()\n",
        "\n",
        "print(f\"Training data size: {train_data.numel()} characters\")\n",
        "print(f\"Testing data size: {test_data.numel()} characters\")\n",
        "\n",
        "# -----------------------------\n",
        "# Triton Kernels\n",
        "# -----------------------------\n",
        "\n",
        "@triton.jit\n",
        "def softmax_kernel(\n",
        "    output_ptr, input_ptr, input_row_stride, output_row_stride, n_cols,\n",
        "    BLOCK_SIZE: tl.constexpr\n",
        "):\n",
        "    row_idx = tl.program_id(0)\n",
        "    col_offsets = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = col_offsets < n_cols\n",
        "\n",
        "    input_row_ptr = input_ptr + row_idx * input_row_stride + col_offsets\n",
        "    output_row_ptr = output_ptr + row_idx * output_row_stride + col_offsets\n",
        "\n",
        "    logits = tl.load(input_row_ptr, mask=mask, other=float('-inf'))\n",
        "    max_logits = tl.max(logits, axis=0)\n",
        "    logits = logits - max_logits\n",
        "    exp_logits = tl.exp(logits)\n",
        "    sum_exp_logits = tl.sum(exp_logits, axis=0) + 1e-6\n",
        "\n",
        "    softmax_output = exp_logits / sum_exp_logits\n",
        "    tl.store(output_row_ptr, softmax_output, mask=mask)\n",
        "\n",
        "@triton.jit\n",
        "def layer_norm_kernel(\n",
        "    x_ptr, weight_ptr, bias_ptr, y_ptr,\n",
        "    N, eps: tl.constexpr,\n",
        "    BLOCK_SIZE: tl.constexpr\n",
        "):\n",
        "    row_idx = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < N\n",
        "\n",
        "    x_offset = x_ptr + row_idx * N + cols\n",
        "    x = tl.load(x_offset, mask=mask, other=0.0)\n",
        "\n",
        "    mean = tl.sum(x, axis=0) / N\n",
        "    x_centered = x - mean\n",
        "    var = tl.sum(x_centered * x_centered, axis=0) / N\n",
        "    rstd = 1.0 / tl.sqrt(var + eps)\n",
        "\n",
        "    w = tl.load(weight_ptr + cols, mask=mask, other=1.0)\n",
        "    b = tl.load(bias_ptr + cols, mask=mask, other=0.0)\n",
        "\n",
        "    y = (x_centered * rstd) * w + b\n",
        "    tl.store(y_ptr + row_idx * N + cols, y, mask=mask)\n",
        "\n",
        "@triton.jit\n",
        "def cross_entropy_loss_kernel(\n",
        "    logits_ptr, targets_ptr, loss_ptr, \n",
        "    n_classes, n_elements,\n",
        "    BLOCK_SIZE: tl.constexpr\n",
        "):\n",
        "    pid = tl.program_id(0)\n",
        "    block_start = pid * BLOCK_SIZE\n",
        "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < n_elements\n",
        "\n",
        "    targets = tl.load(targets_ptr + offsets, mask=mask, other=-1)\n",
        "\n",
        "    row_max = tl.full([BLOCK_SIZE], float('-inf'), dtype=tl.float32)\n",
        "    row_sum = tl.zeros([BLOCK_SIZE], dtype=tl.float32)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        col_offset = offsets * n_classes + i\n",
        "        logit = tl.load(logits_ptr + col_offset, mask=mask, other=float('-inf'))\n",
        "        row_max = tl.maximum(row_max, logit)\n",
        "\n",
        "    loss = tl.zeros([BLOCK_SIZE], dtype=tl.float32)\n",
        "    for i in range(n_classes):\n",
        "        col_offset = offsets * n_classes + i\n",
        "        logit = tl.load(logits_ptr + col_offset, mask=mask, other=float('-inf'))\n",
        "        exp_logit = tl.exp(logit - row_max)\n",
        "        row_sum += exp_logit\n",
        "        loss = tl.where(targets == i, loss - logit + row_max, loss)\n",
        "\n",
        "    loss += tl.log(row_sum)\n",
        "\n",
        "    tl.store(loss_ptr + offsets, loss, mask=mask)\n",
        "\n",
        "@triton.jit\n",
        "def gelu_kernel(\n",
        "    x_ptr, y_ptr, n_elements,\n",
        "    BLOCK_SIZE: tl.constexpr\n",
        "):\n",
        "    offsets = tl.program_id(0) * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offsets, mask=mask)\n",
        "\n",
        "    sqrt_2_over_pi = 0.7978845608028654\n",
        "    coeff = sqrt_2_over_pi * (1 + 0.044715 * x * x)\n",
        "    y = 0.5 * x * (1 + (x * coeff) / (1 + tl.abs(x * coeff)))\n",
        "\n",
        "    tl.store(y_ptr + offsets, y, mask=mask)\n",
        "\n",
        "# -----------------------------------\n",
        "# Triton-accelerated Launch Functions\n",
        "# -----------------------------------\n",
        "\n",
        "class TritonSoftmax(nn.Module):\n",
        "    def forward(self, x):\n",
        "        original_shape = x.shape\n",
        "        if len(original_shape) > 2:\n",
        "            x = x.view(-1, original_shape[-1])\n",
        "        x = x.clamp(-100, 100)\n",
        "        B, N = x.shape\n",
        "        y = torch.empty_like(x)\n",
        "        grid = lambda meta: (B,)\n",
        "        softmax_kernel[grid](\n",
        "            y, x,\n",
        "            x.stride(0), y.stride(0), N,\n",
        "            BLOCK_SIZE=triton.next_power_of_2(N)\n",
        "        )\n",
        "        y = y + 1e-8\n",
        "        y = y / y.sum(dim=-1, keepdim=True)\n",
        "        return y.view(original_shape)\n",
        "    \n",
        "def triton_cross_entropy_loss(logits, targets):\n",
        "    return TritonCrossEntropyLoss.apply(logits, targets)\n",
        "\n",
        "class TritonCrossEntropyLoss(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, logits, targets):\n",
        "        n_elements, n_classes = logits.shape\n",
        "        loss = torch.empty(n_elements, device=logits.device, dtype=logits.dtype)\n",
        "        \n",
        "        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "        \n",
        "        cross_entropy_loss_kernel[grid](\n",
        "            logits, targets, loss,\n",
        "            n_classes, n_elements,\n",
        "            BLOCK_SIZE=1024\n",
        "        )\n",
        "        \n",
        "        ctx.save_for_backward(logits, targets)\n",
        "        return loss.mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        logits, targets = ctx.saved_tensors\n",
        "        batch_size, n_classes = logits.shape\n",
        "\n",
        "        logits_exp = torch.exp(logits - logits.max(dim=-1, keepdim=True).values)\n",
        "        softmax_output = logits_exp / logits_exp.sum(dim=-1, keepdim=True)\n",
        "\n",
        "        grad_input = softmax_output.clone()\n",
        "        grad_input.scatter_add_(1, targets.unsqueeze(1), -torch.ones_like(grad_input))\n",
        "        grad_input *= grad_output.view(-1, 1) / batch_size\n",
        "\n",
        "        return grad_input, None\n",
        "\n",
        "\n",
        "class TritonLayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.normalized_shape = tuple(normalized_shape) if isinstance(normalized_shape, (tuple, list)) else (normalized_shape,)\n",
        "        self.weight = nn.Parameter(torch.ones(self.normalized_shape))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.normalized_shape))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[-len(self.normalized_shape):] == self.normalized_shape, \"Input shape does not match normalized_shape.\"\n",
        "        y = torch.empty_like(x)\n",
        "        x_ = x.reshape(-1, self.normalized_shape[-1])\n",
        "        y_ = y.reshape(-1, self.normalized_shape[-1])\n",
        "        M, N = x_.shape\n",
        "        grid = lambda meta: (triton.cdiv(M, meta['BLOCK_SIZE']),)\n",
        "        layer_norm_kernel[grid](\n",
        "            x_, self.weight, self.bias, y_,\n",
        "            N, eps=self.eps,\n",
        "            BLOCK_SIZE=128\n",
        "        )\n",
        "        return y\n",
        "\n",
        "class TritonGELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        n_elements = x.numel()\n",
        "        y = torch.empty_like(x)\n",
        "        grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "        gelu_kernel[grid](\n",
        "            x, y, n_elements,\n",
        "            BLOCK_SIZE=1024\n",
        "        )\n",
        "        return y\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, seq_length, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.softmax = TritonSoftmax()\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(seq_length, seq_length)).bool())\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, T, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.masked_fill(~self.mask[:T, :T], float('-inf'))\n",
        "        attn = self.softmax(attn)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, T, C)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim, bias=False),\n",
        "            TritonGELU(),\n",
        "            nn.Linear(hidden_dim, dim, bias=False),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, seq_length, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(dim, num_heads, seq_length, dropout)\n",
        "        self.ff = FeedForward(dim, 4 * dim, dropout)\n",
        "        self.ln1 = TritonLayerNorm(dim)\n",
        "        self.ln2 = TritonLayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class NanoGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, dim, num_heads, num_layers, seq_length, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocab_size, dim)\n",
        "        self.position_embedding = nn.Embedding(seq_length, dim)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(dim, num_heads, seq_length, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.ln_f = TritonLayerNorm(dim)\n",
        "        self.head = nn.Linear(dim, vocab_size, bias=False)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "        assert T <= self.seq_length, f\"Input sequence length {T} exceeds model's maximum sequence length {self.seq_length}\"\n",
        "\n",
        "        tok_emb = self.token_embedding(idx)\n",
        "        pos_emb = self.position_embedding(torch.arange(T, device=idx.device))\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def compute_loss(self, logits, targets):\n",
        "        return triton_cross_entropy_loss(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "#----------------------------\n",
        "# Training\n",
        "#----------------------------\n",
        "\n",
        "def train(model, train_data, val_data, batch_size, seq_length, learning_rate, num_epochs):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    def get_batch(split):\n",
        "        data = train_data if split == 'train' else val_data\n",
        "        ix = torch.randint(len(data) - seq_length, (batch_size,))\n",
        "        x = torch.stack([data[i:i+seq_length] for i in ix])\n",
        "        y = torch.stack([data[i+1:i+seq_length+1] for i in ix])\n",
        "        return x.to(model.token_embedding.weight.device), y.to(model.token_embedding.weight.device)\n",
        "\n",
        "    def estimate_mfu(model, dt):\n",
        "        \"\"\" estimate model flops utilization (MFU) in units of A100 bfloat16 peak FLOPS \"\"\"\n",
        "        # first estimate the number of flops we do per iteration.\n",
        "        # see PaLM paper Appendix B as ref: https://arxiv.org/abs/2204.02311\n",
        "        N = sum(p.numel() for p in model.parameters())\n",
        "        L, H, Q, T = model.num_layers, model.num_heads, model.dim // model.num_heads, model.seq_length\n",
        "        flops_per_token = 6*N + 12*L*H*Q*T\n",
        "        flops_per_fwdbwd = flops_per_token * T * batch_size  # multiply by batch size\n",
        "        flops_achieved = flops_per_fwdbwd * (1.0/dt) # per second\n",
        "        flops_promised = 312e12 # A100 GPU bfloat16 peak flops is 312 TFLOPS\n",
        "        mfu = flops_achieved / flops_promised\n",
        "        return mfu\n",
        "\n",
        "    iter_num = 0\n",
        "    best_val_loss = float('inf')\n",
        "    val_losses = []\n",
        "\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        for _ in range(100):  # 100 batches per epoch\n",
        "            iter_num += 1\n",
        "\n",
        "            t_start = time.time()\n",
        "\n",
        "            # Data loading\n",
        "            xb, yb = get_batch('train')\n",
        "            t_data = time.time()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(xb)\n",
        "            t_forward = time.time()\n",
        "\n",
        "            # Loss computation\n",
        "            loss = model.compute_loss(logits, yb)\n",
        "            t_loss = time.time()\n",
        "\n",
        "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
        "                print(f\"Warning: NaN or Inf detected in loss at iteration {iter_num}\")\n",
        "                print(f\"Logits min: {logits.min()}, max: {logits.max()}\")\n",
        "                print(f\"Target min: {yb.min()}, max: {yb.max()}\")\n",
        "                continue\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            t_backward = time.time()\n",
        "\n",
        "            # Optimizer step\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            torch.cuda.synchronize()\n",
        "            t_optim = time.time()\n",
        "\n",
        "            if iter_num % 10 == 0:\n",
        "                dt = t_optim - t_start\n",
        "                dt_data = t_data - t_start\n",
        "                dt_forward = t_forward - t_data\n",
        "                dt_loss = t_loss - t_forward\n",
        "                dt_backward = t_backward - t_loss\n",
        "                dt_optim = t_optim - t_backward\n",
        "                mfu = estimate_mfu(model, dt)\n",
        "                \n",
        "                print(f\"iter {iter_num}: loss {loss.item():.4f}, time {dt*1000:.2f}ms, mfu {mfu*100:.2f}%\")\n",
        "                # print(f\"  Data loading: {dt_data*1000:.2f}ms\")\n",
        "                # print(f\"  Forward pass: {dt_forward*1000:.2f}ms\")\n",
        "                # print(f\"  Loss computation: {dt_loss*1000:.2f}ms\")\n",
        "                # print(f\"  Backward pass: {dt_backward*1000:.2f}ms\")\n",
        "                # print(f\"  Optimizer step: {dt_optim*1000:.2f}ms\")\n",
        "                # print(f\"  Other time: {(dt - dt_data - dt_forward - dt_loss - dt_backward - dt_optim)*1000:.2f}ms\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for _ in range(50):  # 50 val batches\n",
        "                xb, yb = get_batch('val')\n",
        "                logits = model(xb)\n",
        "                val_loss += model.compute_loss(logits, yb).item()\n",
        "        val_loss /= 50\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'Checkpoints/nanoGPT_cpkt.pth')\n",
        "            print(f\"Saved checkpoint for validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        model.train()\n",
        "\n",
        "    return model, val_losses\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Hyperparameters\n",
        "    vocab_size = 65\n",
        "    dim = 384\n",
        "    num_heads = 6\n",
        "    num_layers = 6\n",
        "    seq_length = 256\n",
        "    dropout = 0.1\n",
        "    batch_size = 64\n",
        "    learning_rate = 3e-4\n",
        "    num_epochs = 500\n",
        "\n",
        "    model = NanoGPT(\n",
        "        vocab_size=vocab_size,\n",
        "        dim=dim,\n",
        "        num_heads=num_heads,\n",
        "        num_layers=num_layers,\n",
        "        seq_length=seq_length,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    model.config = type('Config', (), {\n",
        "        'n_layer': num_layers,\n",
        "        'n_head': num_heads,\n",
        "        'n_embd': dim,\n",
        "        'block_size': seq_length\n",
        "    })\n",
        "\n",
        "    # Train config\n",
        "    model, validation_losses = train(\n",
        "        model,\n",
        "        train_data,\n",
        "        test_data,\n",
        "        batch_size=batch_size,\n",
        "        seq_length=seq_length,\n",
        "        learning_rate=learning_rate,\n",
        "        num_epochs=num_epochs\n",
        "    )\n",
        "\n",
        "    # Load checkpoint\n",
        "    model.load_state_dict(torch.load('checkpoints/nanoGPT_cpkt.pth', weights_only=True))\n",
        "\n",
        "    # Generate sample\n",
        "    model.eval()\n",
        "    start_text = \"Once upon\"\n",
        "    input_ids = encode(start_text).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(240):\n",
        "            logits = model(input_ids)\n",
        "            next_token_logits = logits[:, -1, :]\n",
        "            next_token_logits = torch.clamp(next_token_logits, -100, 100)\n",
        "            probs = F.softmax(next_token_logits, dim=-1) + 1e-8\n",
        "            probs = probs / probs.sum()\n",
        "            if torch.isnan(probs).any() or torch.isinf(probs).any():\n",
        "                probs = torch.ones_like(probs) / probs.shape[-1]\n",
        "            \n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "    generated_text = decode(input_ids[0].cpu())\n",
        "    print(\"Generated Text:\")\n",
        "    print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
